# Theory of Change: Youth-Led AI Safety

> **Logic Model: How inputs translate to safer digital futures for youth.**

## 1. Logic Model

| Stage | Description | Key Components |
| :--- | :--- | :--- |
| **Problem** | Youth are the primary users of AI but are excluded from safety evaluations. Existing safeguards fail to catch context-specific harms (bullying, misinformation). | Lack of evidence; Unsafe products; Disempowered youth. |
| **Inputs** | Resources invested. | Grant Funding; Technical Toolkit Code; Expert Staff; Youth Volunteers; NGO Partnerships. |
| **Activities** | What we do. | Develop open-source audit tools; Train NGO facilitators; Conduct youth-led safety audits; Analyze failure modes; Publish findings. |
| **Outputs** | Direct products. | 1 Toolkit (v1.0); 50 Youth Safety Audits conducted; 1 Policy Brief published; 200 Youth trained in AI literacy. |
| **Outcomes** | Short/Medium changes. | **Short**: Increased youth critical thinking (+20% literacy); Reduced immediate risk exposure. **Medium**: NGOs gain technical audit capacity; AI product teams fix identified bugs. |
| **Impact** | Long-term goal. | A safer, more transparent AI ecosystem for youth across EMEA; Evidence-based policy regulation. |

## 2. Measurable Indicators (KPIs)

1.  **Youth Engagement**: Number of youth auditors completing the full training cycle (Target: TODO).
2.  **Audit Volume**: Number of unique AI model interactions logged and analyzed (Target: TODO).
3.  **Safety Efficacy**: Number of distinct safety vulnerabilities (failure modes) identified and reported (Target: TODO).
4.  **Literacy Gain**: Average percentage improvement in pre/post AI literacy assessment scores (Target: TODO%).
5.  **Policy Reach**: Number of downloads/citations of the Policy Brief (Target: TODO).
6.  **Product Impact**: Number of bug reports acknowledged or fixed by AI developers (Target: TODO).
7.  **Partner Adoption**: Number of NGOs independently running the toolkit (Target: TODO).
8.  **Scalability**: Cost per youth auditor trained (Target: <$X TODO).

## 3. Critical Assumptions

-   **Motivation**: Youth are interested in "breaking" AI models for safety and not just passive consumption.
-   **Access**: Partner NGOs have reliable internet and devices (tablets/laptops).
-   **Responsiveness**: AI product teams (e.g., OpenAI, Google) are open to receiving structured feedback from civil society.
-   **Safety**: The provided safeguards (moderation, filters) are sufficient to prevent psychological harm during testing.
