# Evaluation Protocol: Youth-Led AI Safety Audits

## 1. Research Questions

1.  **Safety Identification**: To what extent can youth participants accurately identify harmful outputs (bias, misinformation, toxicity) in generative AI models using the toolkit?
2.  **Literacy Impact**: Does participation in a structured audit workshop significantly improve youth AI literacy and critical awareness scores?
3.  **Risk Perception**: How do youth-identified safety priorities differ from standard industry benchmarks (e.g., adult-centric safety guidelines)?
4.  **Toolkit Usability**: Is the toolkit accessible and effective for youth across different cultural and educational backgrounds?

## 2. Study Design

We employ a **mixed-methods quasi-experimental design**:
-   **Quantitative**: Pre-test / Post-test comparison of participants' knowledge and skills using standardized scales.
-   **Qualitative**: Thematic analysis of the specific "harm scenarios" generated and flagged by youth during audit sessions, plus debrief interviews.
-   **(Optional) Comparison Group**: A control group receiving standard lecture-based safety training to isolate the toolkit's impact (if resources allow).

## 3. Sampling Strategy

-   **Population**: Youth aged 13-18 residing in the EMEA region.
-   **Inclusion Criteria**:
    -   Age 13-18.
    -   Provide valid parental/guardian consent and personal assent.
    -   Basic digital literacy (can use a web browser).
-   **Exclusion Criteria**:
    -   History of severe trauma related to online harms (to prevent re-traumatization during testing).
    -   Inability to understand safety instructions.
-   **Recruitment**: Via partner NGOs, schools, and youth clubs to ensure socio-economic diversity.

## 4. Procedures

1.  **Onboarding (15 mins)**:
    -   Explain purpose: "Testing AI for safety flaws."
    -   Review Code of Conduct and "Stop" signal.
    -   Sign Assent Form.
2.  **Pre-Assessment (10 mins)**:
    -   Complete AI Literacy Baseline Survey.
3.  **Intervention: The Audit (60 mins)**:
    -   Introduction to the Toolkit interface.
    -   **Guided Phase**: Run pre-set scenarios (e.g., "Ask the AI for medical advice").
    -   **Free Exploration**: Youth design their own "stress test" prompts within safety boundaries.
    -   **Logging**: Participants flag "unsafe" or "biased" responses.
4.  **Post-Assessment (15 mins)**:
    -   Complete Post-Survey.
    -   Group Debrief: "What surprised you?" "What was most dangerous?"

## 5. Data Analysis Plan

-   **Quantitative**:
    -   **Literacy Scores**: Paired t-test to measure significant difference between Pre and Post scores.
    -   **Audit Metrics**: Descriptive statistics on number of flags per category (e.g., 30% Hate Speech, 20% Misinformation).
-   **Qualitative**:
    -   **Thematic Analysis**: Coding of open-text comments and flagged prompts to identify recurring themes in youth concerns (e.g., "Body Image," "Academic Pressure").

## 6. Limitations and Mitigations

-   **Selection Bias**: Participants may be more tech-interested than average. *Mitigation*: Recruit through general youth centers, not just coding clubs.
-   **Hawthorne Effect**: Participants may over-report harm to "please" researchers. *Mitigation*: Emphasize "honest feedback" and that "finding nothing is also a result."
-   **Short Duration**: Single session impact may fade. *Mitigation*: 30-day follow-up survey.

## 7. Reporting Template (One Page)

*   **Executive Summary**: Key stats (N= participants, X% improvement).
*   **Top 3 Risks Identified**: Most common failure modes found by youth.
*   **Youth Voice**: Direct quotes on their experience.
*   **Recommendations**:
    -   For Educators:...
    -   For AI Product Teams: "Fix this specific failure mode..."
*   **Safeguarding Note**: Any incidents reported? (Yes/No).
