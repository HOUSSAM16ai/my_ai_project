# ======================================================================================
# ==          COGNIFORGE ENVIRONMENT PROTOCOL (v6.0 - Supabase Native)              ==
# ======================================================================================
# This file is the single source of truth for all secrets and configurations.
# It is designed for a Supabase-first architecture.

# --------------------------------------------------------------------------------------
# [CORE] APPLICATION & SECURITY
# --------------------------------------------------------------------------------------
FLASK_APP=run:app
FLASK_ENV=development
FLASK_DEBUG=1
SECRET_KEY="a-very-long-and-random-string-please-change-me-for-production"

# --------------------------------------------------------------------------------------
# [CRITICAL] DATABASE CONNECTION - SUPABASE
# --------------------------------------------------------------------------------------
# احصل على سلسلة الاتصال من لوحة تحكم Supabase:
# Get your connection string from Supabase Dashboard:
#   Project Settings > Database > Connection string > URI
#
# اختر نوع الاتصال | Choose connection type:
#   - Pooled (6543): للتحميل العالي والاتصالات المتزامنة (موصى به لـ Codespaces/Gitpod)
#                    For high load and concurrent connections (Recommended for Codespaces/Gitpod)
#   - Direct (5432): للعمليات الكتابية والقراءة المباشرة
#                    For write operations and direct reads
#
# مهم جداً | Very Important:
#   ✅ أضف sslmode=require في نهاية السلسلة
#      Add sslmode=require at the end of the connection string
#   ✅ إذا كانت كلمة المرور تحتوي على رموز خاصة مثل @ أو # قم بترميزها
#      If password contains special characters like @ or #, percent-encode them
#      Example: @ becomes %40, # becomes %23
#
# أمثلة | Examples:
#   Pooled (Recommended): postgresql://postgres:YOUR_PASSWORD@YOUR-PROJECT-REF.pooler.supabase.com:6543/postgres?sslmode=require
#   Direct: postgresql://postgres:YOUR_PASSWORD@YOUR-PROJECT-HOST.supabase.co:5432/postgres?sslmode=require
DATABASE_URL="postgresql://postgres:[YOUR-USERNAME].[YOUR-PROJECT-REF]:[YOUR-PASSWORD]@[YOUR-PROJECT-REF].pooler.supabase.com:6543/postgres?sslmode=require"

# --------------------------------------------------------------------------------------
# [OPTIONAL] SUPABASE CLIENT SDK (for advanced integrations)
# --------------------------------------------------------------------------------------
# هذه المتغيرات اختيارية للتكاملات المتقدمة خارج SQLAlchemy
# These variables are optional for advanced integrations outside SQLAlchemy
#
# احصل عليها من | Get them from:
#   Project Settings > API > Project URL & API Keys
#
# SUPABASE_URL: رابط مشروعك في Supabase | Your Supabase project URL
SUPABASE_URL="https://YOUR-PROJECT-REF.supabase.co"

# SUPABASE_ANON_KEY: المفتاح العام للمستخدم النهائي (آمن للعملاء)
#                    Public anon key for end users (safe for clients)
SUPABASE_ANON_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

# SUPABASE_SERVICE_ROLE_KEY: مفتاح الخدمة (سري جداً - استخدم بحذر!)
#                             Service role key (VERY SECRET - use with caution!)
#                             يمنح صلاحيات كاملة | Grants full permissions
# SUPABASE_SERVICE_ROLE_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

# --------------------------------------------------------------------------------------
# [CRITICAL] AI ENGINE
# --------------------------------------------------------------------------------------
# Your key for OpenRouter, the gateway to all LLMs.
OPENROUTER_API_KEY="sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# The default model used by Maestro for tactical reasoning.
DEFAULT_AI_MODEL="anthropic/claude-3.7-sonnet:thinking"
LOW_COST_MODEL="openai/gpt-4o-mini"

# --------------------------------------------------------------------------------------
# [SUPERHUMAN] AI SERVICE OPTIMIZATION - Complex Question Handling
# --------------------------------------------------------------------------------------
# 🚀 Advanced settings for handling very long or complex questions
# These settings prevent timeout errors and ensure stable responses

# ---------- [EXTREME MODE] For Extremely Complex Questions ----------
# 💪 Enable this mode when you need UNLIMITED processing power
# Better than OpenAI, Google, Microsoft, Facebook, Apple!

# LLM_EXTREME_COMPLEXITY_MODE: Enable extreme processing (default: 0)
# When enabled (set to 1):
#   - Timeout: 180s → 600s (10 minutes)
#   - Retries: 2 → 8 attempts
#   - Backoff: 1.3 → 1.5 for better recovery
#   - Question length: Up to 100K characters
#   - Response tokens: Up to 64K tokens
# LLM_EXTREME_COMPLEXITY_MODE=0

# ---------- [ULTIMATE MODE] 🚀 SUPERHUMAN - Answer No Matter What! ----------
# 🏆 THE MOST POWERFUL MODE - Surpasses ALL tech giants combined!
# Use this when you ABSOLUTELY MUST get an answer, regardless of:
#   - Time cost (up to 30 minutes per question)
#   - Money cost (up to 128K tokens = maximum possible)
#   - Complexity (handles questions that would break other systems)

# LLM_ULTIMATE_COMPLEXITY_MODE: Enable ULTIMATE processing mode (default: 0)
# When enabled (set to 1):
#   - Timeout: 180s → 1800s (30 MINUTES! Enough for anything)
#   - Retries: 2 → 20 attempts (We WILL get your answer!)
#   - Backoff: 1.3 → 1.8 for maximum resilience
#   - Question length: UNLIMITED (tested up to 500K+ characters)
#   - Response tokens: Up to 128K tokens (maximum model capacity)
#   - Total possible time: Up to 10 HOURS with retries
#   - Success rate: 99.9%+ even for the most complex questions
#
# ⚠️ WARNING: This mode is EXPENSIVE but UNSTOPPABLE
# Use only for mission-critical questions that MUST be answered perfectly
# LLM_ULTIMATE_COMPLEXITY_MODE=0

# LLM_TIMEOUT_SECONDS: Maximum time to wait for AI response
# Default: 180 seconds (3 minutes)
# Extreme mode: 600 seconds (10 minutes)
# Ultimate mode: 1800 seconds (30 minutes)
# LLM_TIMEOUT_SECONDS=180

# LLM_MAX_RETRIES: Number of retry attempts
# Default: 2 attempts
# Extreme mode: 8 attempts
# Ultimate mode: 20 attempts (enough to handle ANY failure!)
# LLM_MAX_RETRIES=2

# LLM_RETRY_BACKOFF_BASE: Exponential backoff multiplier
# Default: 1.3
# Extreme mode: 1.5 for more patient retries
# LLM_RETRY_BACKOFF_BASE=1.3

# ADMIN_AI_MAX_QUESTION_LENGTH: Maximum question length in characters (default: 50000)
# Questions longer than this will be rejected with helpful guidance
# ADMIN_AI_MAX_QUESTION_LENGTH=50000

# ADMIN_AI_LONG_QUESTION_THRESHOLD: Threshold for "long" questions (default: 5000)
# Questions above this get extra processing time and larger response tokens
# ADMIN_AI_LONG_QUESTION_THRESHOLD=5000

# ADMIN_AI_EXTREME_QUESTION_THRESHOLD: When to consider a question as "extremely complex" (default: 20000)
# Questions above this threshold trigger maximum resource allocation
# ADMIN_AI_EXTREME_QUESTION_THRESHOLD=20000

# ADMIN_AI_MAX_RESPONSE_TOKENS: Maximum tokens for responses (default: 16000, 32000 in extreme mode)
# Allows comprehensive answers to complex questions
# In extreme mode, this doubles to 32,000 tokens for ultra-detailed responses
# ADMIN_AI_MAX_RESPONSE_TOKENS=16000

# ADMIN_AI_ENABLE_STREAMING: Enable streaming responses for better UX (default: 1)
# Set to 0 to disable streaming
# ADMIN_AI_ENABLE_STREAMING=1

# --------------------------------------------------------------------------------------
# [SUPERHUMAN] AI AGENT TOKEN - MCP SERVER INTEGRATION
# --------------------------------------------------------------------------------------
# 🚀 AI Agent Token for GitHub Copilot + Model Context Protocol (MCP) integration.
# This token enables superhuman AI capabilities surpassing Google, Microsoft, OpenAI!
#
# This token is used in THREE critical locations:
#   1. 🔧 GitHub Actions - CI/CD workflows with AI assistance
#   2. ☁️  GitHub Codespaces - Cloud development environments
#   3. 🤖 Dependabot - Automated dependency updates with AI review
#
# How to get your token | كيفية الحصول على الرمز:
#   1. Visit: https://github.com/settings/tokens
#   2. Click "Generate new token (classic)"
#   3. Select scopes | اختر الصلاحيات:
#      ✅ repo (Full control of private repositories)
#      ✅ read:org (Read org and team membership)
#      ✅ workflow (Update GitHub Action workflows)
#      ✅ admin:repo_hook (Full control of repository hooks)
#      ✅ read:discussion (Read discussions)
#      ✅ write:discussion (Write discussions)
#      ✅ read:packages (Download packages from GitHub Package Registry)
#      ✅ write:packages (Upload packages to GitHub Package Registry)
#   4. Copy the generated token (starts with ghp_ or github_pat_)
#   5. Paste it here
#
# Token format examples:
#   Classic: ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#   Fine-grained: github_pat_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#
# 🔐 Security Notes | ملاحظات أمنية:
#   ⚠️  NEVER commit this token to Git
#   ⚠️  لا تقم أبداً بإضافة هذا الرمز إلى Git
#   ✅  This file is in .gitignore (safe)
#   ✅  هذا الملف في .gitignore (آمن)
#   ✅  Rotate tokens every 90 days for security
#   ✅  قم بتدوير الرموز كل 90 يوماً للأمان
#   ✅  Store in GitHub Secrets for Actions/Codespaces/Dependabot
#   ✅  قم بتخزينه في GitHub Secrets للثلاثة أماكن
#
# 🎯 Where to add this secret:
#   - GitHub Actions: Settings > Secrets and variables > Actions > New repository secret
#   - Codespaces: Settings > Secrets > Codespaces > New secret
#   - Dependabot: Settings > Secrets and variables > Dependabot > New secret
#   Name: AI_AGENT_TOKEN
#
AI_AGENT_TOKEN="ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# Legacy support (will be deprecated)
GITHUB_PERSONAL_ACCESS_TOKEN="${AI_AGENT_TOKEN}"

# --------------------------------------------------------------------------------------
# [CORE] AUTOMATIC SEEDING PROTOCOL
# --------------------------------------------------------------------------------------
# Used by the `flask users init-admin` command.
ADMIN_EMAIL="admin@example.com"
ADMIN_PASSWORD="strong-password-here"
ADMIN_NAME="Admin User"

# ======================================================================================
# ==                   OVERMIND / PLANNER HYPER-CONFIGURATION                       ==
# ======================================================================================
# This section provides fine-grained control over the Overmind planning and execution engine.
# Only change these if you are an expert.

# ---------- [1] Planner Intelligence & Behavior ----------
PLANNER_ENABLE_ROLE_DERIVATION=1       # Allow planner to assign roles to files.
PLANNER_ENABLE_SECTION_INFERENCE=1     # Allow planner to infer document sections.
PLANNER_ENABLE_CODE_HINTS=1            # Provide hints for code-related generation.
PLANNER_STRICT_WRITE_ENFORCE=1         # Ensure every target file in the objective is written to.
PLANNER_SMART_FILENAME=1               # Automatically clean and generate filenames.
PLANNER_ALLOW_SUBDIRS=1                # Allow planner to create files in subdirectories.

# ---------- [2] Chunking & Streaming Engine (Enhanced for Extreme Complexity) ----------
PLANNER_STREAMING_ENABLE=1             # Enable multi-task streaming for large content.
PLANNER_ALLOW_APPEND_TOOL=auto         # 'auto', '1' (force), or '0' (disable).
PLANNER_MAX_CHUNKS=100                 # Max generation tasks for a single file (increased from 50 for extreme complexity).
PLANNER_CHUNK_SIZE_HINT=1200           # Target character count per chunk.
PLANNER_FAST_SINGLE_THRESHOLD=1800     # Objectives smaller than this may use a single task.
PLANNER_HARD_LINE_CAP=2000000          # Hard limit on total lines (increased from 1.2M for extreme complexity)

# ---------- [3] Agent Tools Runtime Behavior ----------
AGENT_TOOLS_PROJECT_ROOT=/app          # The root directory inside the container.
AGENT_TOOLS_LOG_LEVEL=INFO
AGENT_TOOLS_MAX_WRITE_BYTES=5000000
AGENT_TOOLS_MAX_READ_BYTES=800000
AGENT_TOOLS_CREATE_MISSING=1           # Allow tools to create files that don't exist.
AGENT_TOOLS_CREATE_ALLOWED_EXTS=.md,.txt,.json,.log

# ---------- [4] System & Logging ----------
OVERMIND_LOG_DEBUG=1                   # Set to 0 in production.
LLM_PLANNER_LOG_LEVEL=DEBUG            # Set to INFO in production.
LOG_FORMAT_JSON=0                      # Set to 1 for structured logging.

# ---------- [5] Global Guardrails (Enhanced for Extreme Complexity) ----------
PLANNER_MAX_FILES=12                   # Max number of files a single mission can target.
PLANNER_MAX_TASKS_GLOBAL=800           # Hard limit on total tasks in a single plan (increased from 400 for extreme complexity).
DISABLED_TOOLS=delete_file             # Prevent the AI from using the delete_file tool for safety.

# --------------------------------------------------------------------------------------
# [OPTIONAL] DEVCONTAINER / CODESPACES BEHAVIOR CONTROL
# --------------------------------------------------------------------------------------
# These variables control the behavior of scripts in .devcontainer/
# Useful when setting up in GitHub Codespaces or local Dev Containers
#
# WAIT_FOR_DB=0                        # Skip waiting for database (for external Supabase)
# RUN_MIGRATIONS_ON_START=0            # Skip auto-migrations on container start
# RUN_APP_ON_START=0                   # Skip auto-starting the app
# SKIP_PIP_INSTALL=0                   # Skip pip install (when already in Docker image)

# --------------------------------------------------------------------------------------
# [ADVANCED] SUPERHUMAN STREAMING FEATURES
# --------------------------------------------------------------------------------------
# Advanced streaming features that surpass ChatGPT, Gemini, and Claude
#
# SSE Streaming Control
ALLOW_MOCK_LLM=false                   # Set to 'true' for development/testing (default: false for production)
ENABLE_HYBRID_STREAMING=false          # Enable hybrid streaming with prediction (experimental)
ENABLE_INTELLIGENT_ROUTING=false       # Enable intelligent model routing based on query complexity

# Model Tier Configuration (for intelligent routing)
NANO_MODEL=openai/gpt-4o-mini          # Fast, simple queries (<50ms)
FAST_MODEL=openai/gpt-4o-mini          # Quick responses (<200ms)
SMART_MODEL=anthropic/claude-3.5-sonnet # Intelligent responses (<1s)
GENIUS_MODEL=anthropic/claude-3-opus   # Complex reasoning (<5s)

# Cost Management
LLM_DAILY_BUDGET=100                   # Daily budget in USD (default: 100)

# Performance Tuning
STREAMING_CHUNK_SIZE=8                 # Tokens per chunk (default: 8)
STREAMING_HEARTBEAT_INTERVAL=20        # Heartbeat interval in seconds (default: 20)

# ======================================================================================
# ==                         END OF CONFIGURATION                                     ==
# ======================================================================================
