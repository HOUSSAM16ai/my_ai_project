# Core Proposal (Draft)

> **Word Count**: Approx. 450 words. Check limit.

## Project Title: Youth AI Safety Toolkit

**Objectives**
Our primary objective is to empower youth (ages 13-18) to conduct independent safety audits of Generative AI models, producing verifiable evidence of algorithmic harm. By bridging the gap between youth lived experience and technical safety evaluations, we aim to: (1) Develop an open-source, age-appropriate auditing toolkit; (2) Pilot this methodology with 50 youth participants to identify specific failure modes (e.g., bullying, radicalization); and (3) Publish actionable policy briefs and technical reports to inform safer AI regulation and product development in the EMEA region.

**Methods**
We employ a participatory research design structured in four phases:
1.  **Design (Months 1-2)**: We will co-create safety scenarios with youth advisors and technical experts, ensuring the toolkit interface is engaging and psychologically safe. The curriculum focuses on identifying bias, misinformation, and toxic content.
2.  **Pilot (Months 3-4)**: We will conduct supervised workshops with partner NGOs. Participants will use the toolkit to "red team" popular AI models against youth-specific risk scenarios. All sessions follow strict safeguarding protocols (see `SAFEGUARDING.md`).
3.  **Measure (Month 5)**: We will analyze audit logs to quantify failure rates and assess the impact on participants' AI literacy using pre/post surveys.
4.  **Publish (Month 6)**: Findings will be synthesized into a public report and a policy brief, distributed to key stakeholders.

**Timeline**
-   **Month 1**: Repository setup and partner recruitment (Target: 2 NGOs).
-   **Month 2**: Toolkit v1.0 development and safeguarding review.
-   **Month 3**: Pilot workshops commence (Target: 25 youth).
-   **Month 4**: Second wave of pilots (Target: 25 youth) and initial data analysis.
-   **Month 5**: Refinement of toolkit based on user feedback; drafting of policy brief.
-   **Month 6**: Final Report launch, open-sourcing of dataset (anonymized), and dissemination webinar.

**Deliverables**
1.  **The Toolkit**: A functional, open-source software suite for youth-led AI auditing, including technical modules for text and image analysis.
2.  **The Evidence Base**: A dataset of youth-identified AI failure modes, proving where current safeguards fall short.
3.  **Policy Brief**: A concise document for regulators highlighting specific risks to youth wellbeing.
4.  **Educational Curriculum**: A verified training pack for educators to teach AI safety in schools.

**Value to Stakeholders**
For **policymakers**, we provide the missing link: independent, youth-generated data to justify evidence-based regulation. For **AI product teams**, we offer high-quality, structured feedback on edge cases they often miss. For **youth-serving NGOs**, we provide a scalable, ready-to-use program that builds digital resilience. This project transforms youth from vulnerable subjects into active agents of AI safety.
