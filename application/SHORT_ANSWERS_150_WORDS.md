# Short Answers (Drafts)

> **Instructions**: Each answer is drafted to be â‰¤150 words. Check specific character limits in the portal before pasting.

## 1. What specific risks or opportunities does this project address? (Max 150 words)

Generative AI presents critical risks to youth wellbeing, including exposure to subtle bullying, radicalization, body image reinforcement, and misinformation. However, current safety evaluations are conducted by adults and often miss these context-specific harms. This project addresses the "safety gap" by empowering youth to audit AI models themselves. The opportunity is twofold: first, to generate independent, verifiable evidence of algorithmic harm that is currently invisible to regulators; and second, to transform youth from passive consumers into active safety researchers. By validating a toolkit for youth-led auditing, we create a scalable mechanism to identify and mitigate risks before they cause widespread psychological harm.

## 2. Why is this output useful to your target stakeholders? (Max 150 words)

Our toolkit serves three distinct needs. For **policymakers**, it provides independent, data-driven evidence of AI risks to inform necessary regulation, filling the current void of youth-centric data. For **educators and NGOs**, it offers a ready-made, safe curriculum to teach critical AI literacy through practical "red teaming," moving beyond theoretical lessons. For **AI product teams**, it translates vague safety concerns into structured, technical bug reports (failure modes) that can be directly remediated. This multi-stakeholder utility ensures the project drives change at the regulatory, community, and technical levels simultaneously.

## 3. Who will benefit from this project and what is the expected reach? (Max 150 words)

**Direct beneficiaries** are the youth participants (aged 13-18) in our pilot workshops, who will gain advanced digital literacy and critical thinking skills. We target training TODO youth auditors in the first year. **Indirect beneficiaries** include the broader youth population across EMEA who use AI tools; they benefit from the safer product features and stronger regulations resulting from our findings. Partner NGOs also benefit by gaining the technical capacity to run their own safety programs. We aim to distribute the toolkit to TODO organizations, potentially reaching TODO indirect beneficiaries through improved safeguards in major AI models.

## 4. How will you measure improvement or impact? (Max 150 words)

We track impact through eight specific Key Performance Indicators (KPIs) detailed in our Measurement Plan. Key metrics include: (1) **Efficacy**: The number of distinct safety vulnerabilities identified and reported to AI labs; (2) **Literacy**: The percentage improvement in participants' critical thinking scores, measured via pre- and post-workshop assessments; (3) **Adoption**: The number of partner NGOs actively using the toolkit; and (4) **Policy Influence**: The number of citations of our findings in policy briefs or regulatory consultations. We will conduct a 30-day follow-up to measure long-term retention of safety skills. All metrics are open-source to ensure accountability.
