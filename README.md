# Youth AI Safety Toolkit

> **Open-source toolkit for youth-led AI safety audits, providing verifiable evidence of algorithmic harm and actionable safeguards for policymakers, educators, and product teams.**

## The Problem
Youth are the primary users of generative AI but are largely excluded from safety evaluations. Current safeguards often fail to detect context-specific harms—such as subtle bullying, radicalization, body image reinforcement, and misinformation—that disproportionately affect young people's wellbeing. There is a critical lack of independent, youth-centric evidence to guide safer AI development.

## What We Deliver
1.  **The Toolkit**: A technical and methodological suite for youth-serving organizations to conduct safe, structured AI safety audits.
2.  **The Evidence**: Verifiable, data-driven reports on AI safety gaps, produced directly from youth testing and evaluation.

## Primary Contribution
-   **Evaluation of Safeguards**: Rigorous testing of AI models against youth-specific risk scenarios.
-   **Evidence for Policymakers & Product Teams**: Translating qualitative user experiences into quantitative safety metrics.

## Who Benefits
-   **Youth-Serving NGOs**: Gain capacity to run independent safety programs and advocate for their communities.
-   **Educators & Parents**: Access practical tools to teach critical AI literacy and safety.
-   **Policymakers**: Receive independent data on AI risks to inform regulation and guidelines.
-   **AI Product Teams**: Get structured, actionable feedback on model failure modes to improve safety filters.

## Methods at a Glance
1.  **Design**: Create youth-appropriate audit scenarios and safety curriculums.
2.  **Pilot**: Conduct controlled testing sessions with youth auditors under supervision.
3.  **Measure**: Quantify harms, success rates of safeguards, and literacy improvements.
4.  **Iterate**: Refine tools and protocols based on pilot feedback.
5.  **Publish**: Release open-access evidence and policy briefs.

## Impact Measurement
We track the following key performance indicators (KPIs):
-   Number of youth auditors trained in safety evaluation (Target: TODO).
-   Number of AI models audited for youth safety risks (Target: TODO).
-   Number of distinct safety vulnerabilities identified and reported (Target: TODO).
-   Number of policy briefs and technical reports published (Target: TODO).
-   Adoption rate of the toolkit by partner NGOs (Target: TODO).
-   Percentage improvement in youth AI literacy scores (Pre/Post) (Target: TODO%).
-   Reduction in harmful content exposure in controlled pilot groups (Target: TODO%).
-   Number of engagements with AI product teams or policymakers (Target: TODO).

## Ethics & Safeguarding Snapshot
-   **Safeguarding**: We operate under strict child protection protocols. All interactions are supervised. See [`SAFEGUARDING.md`](SAFEGUARDING.md).
-   **Consent**: Mandatory informed consent from guardians and assent from youth participants.
-   **Wellbeing**: "Do No Harm" principle is paramount. Psychological support protocols are in place for any exposure to harmful content.

## Data Protection Snapshot
-   **Privacy by Design**: We adhere to GDPR and COPPA principles. We do not collect PII from minors.
-   **Data Minimization**: Only aggregate, anonymized data is stored for analysis.
-   **Security**: All data is encrypted at rest and in transit. See [`DATA_PROTECTION.md`](DATA_PROTECTION.md).

## Independence & Transparency
This project is an independent initiative. We are not funded by AI product companies for this specific audit work, ensuring unbiased evaluation. All tools, methodologies, and findings are published open-source to foster trust and reproducibility.

## Repository Structure
-   `app/`: Core application logic and microservices for the toolkit.
-   `docs/`: Methodologies, evaluation protocols, and impact plans.
    -   `docs/IMPACT_MEASUREMENT_PLAN.md`: Detailed KPIs and measurement tools.
    -   `docs/EVALUATION_PROTOCOL.md`: Scientific approach to safety audits.
    -   `docs/STAKEHOLDER_OUTPUTS.md`: Templates for reports and briefs.
-   `toolkit/`: (TODO: Placeholder) Specific audit scripts and scenarios.
-   `research/`: (TODO: Placeholder) Published reports and findings.

## Quick Start for Partners
1.  **Review Protocols**: Read [`SAFEGUARDING.md`](SAFEGUARDING.md) and [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md) first.
2.  **Clone the Repo**:
    ```bash
    git clone https://github.com/NorthAfricanAISafetyLab/youth-ai-safety-toolkit.git
    cd youth-ai-safety-toolkit
    ```
3.  **Setup Environment**:
    ```bash
    # TODO: Add setup script instructions
    cp .env.example .env
    ```
4.  **Run the Toolkit**:
    ```bash
    # Start the platform
    docker compose up --build
    ```

## Legal Host
-   **Organization**: North African AI Safety Lab
-   **Principal Investigator**: Houssam Benmerah
-   **Registration Number**: TODO: Enter Registration Number
-   **Address**: TODO: Enter Organization Address
-   **Contact**: TODO: Enter Contact Email
