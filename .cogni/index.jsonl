{"id": 1, "path": "CONTRIBUTING.md", "start": 0, "end": 1200, "len": 1200, "preview": "# إرشادات المساهمة في CogniForge\n\nمرحبًا بك أيها المهندس! هذا المستند يحتوي على أفضل الممارسات والنصائح لتطوير المشروع.\n\n## إعداد اختصارات الطرفية (لزيادة الإنتاجية الخارقة)\n\nلجعل التفاعل مع نظام CLI"}
{"id": 2, "path": "CONTRIBUTING.md", "start": 1000, "end": 2200, "len": 1200, "preview": "pose exec web bash\"\n\necho \"✅ CogniForge aliases loaded.\"\n\n\nsource ~/.bashrc\n\n\n\nبالتأكيد. دعنا نوضح الأمر خطوة بخطوة وببساطة مطلقة.\n\nالمشكلة: لقد قمنا بإنشاء اختصارات رائعة (c-index, c-generate)، ولكن"}
{"id": 3, "path": "CONTRIBUTING.md", "start": 2000, "end": 3200, "len": 1200, "preview": "ذا الملف الجديد في محرر VS Code. يمكنك العثور عليه في قائمة الملفات على اليسار.\n\nالخطوة 4: اكتب \"الإرشادات\"\n\nانسخ كل النص الموجود في المربع الرمادي أدناه والصقه بالكامل داخل ملف CONTRIBUTING.md.\n\ncode"}
{"id": 4, "path": "CONTRIBUTING.md", "start": 3000, "end": 4200, "len": 1200, "preview": "------------\n# CogniForge: Supercharged CLI Aliases\n# --------------------------------------------------\n\n# الاختصار الرئيسي الذي يربط الطرفية بتطبيق Flask داخل الحاوية\nalias cogniforge=\"docker-compos"}
{"id": 5, "path": "CONTRIBUTING.md", "start": 4000, "end": 4703, "len": 703, "preview": "ND\n#### **الخطوة 5: احفظ \"كتاب الإرشادات\" في GitHub**\n\nالآن بعد أن أصبح لدينا \"دليل الإرشادات\"، يجب أن نجعله جزءًا دائمًا من المشروع.\n\n1.  **اذهب إلى الطرفية الرئيسية.**\n2.  **أضف الملف الجديد إلى Git"}
{"id": 6, "path": "Dockerfile", "start": 0, "end": 1200, "len": 1200, "preview": "# Dockerfile - Version 8.0 (The Dual-Authority Protocol)\n\n# --- المرحلة الأولى: الورشة (Builder Stage) ---\nFROM python:3.12-bullseye AS builder\nENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1\nRUN apt"}
{"id": 7, "path": "Dockerfile", "start": 1000, "end": 1397, "len": 397, "preview": "al/bin:${PATH}\"\n\n# 3. إنشاء المستخدم والمجموعة.\nRUN addgroup --system appgroup && adduser --system --group appuser\n\n# 4. نسخ وتثبيت كل شيء كـ root.\nWORKDIR /app\nCOPY --from=builder /app/wheels /wheels"}
{"id": 8, "path": "config.py", "start": 0, "end": 1200, "len": 1200, "preview": "# config.py - The Hyper-Configurable, Resilient Constitution (v3.0 - Enterprise Ready)\n\nimport os\nfrom dotenv import load_dotenv\n\nbasedir = os.path.abspath(os.path.dirname(__file__))\nload_dotenv(os.pa"}
{"id": 9, "path": "config.py", "start": 1000, "end": 2200, "len": 1200, "preview": "efaults to allow easy overriding via .env\n    DEFAULT_AI_MODEL = os.environ.get('DEFAULT_AI_MODEL', 'openai/gpt-4o')\n    AGENT_MAX_STEPS = int(os.environ.get('AGENT_MAX_STEPS', 5))\n\n    # --- [THE RES"}
{"id": 10, "path": "config.py", "start": 2000, "end": 2696, "len": 696, "preview": "_CSRF_ENABLED = False\n    # We disable pooling for the simple in-memory SQLite DB as it's not needed.\n    SQLALCHEMY_ENGINE_OPTIONS = {}\n    # We also don't need a real API key for most tests.\n    OPE"}
{"id": 11, "path": "docker-compose.yml", "start": 0, "end": 1200, "len": 1200, "preview": "# docker-compose.yml (The Loop-Breaker Protocol - TEMPORARY)\nservices:\n  # Migrations service remains unchanged.\n  migrations:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    container_na"}
{"id": 12, "path": "docker-compose.yml", "start": 1000, "end": 1519, "len": 519, "preview": "e\n    restart: unless-stopped\n    env_file:\n      - .env\n    command: gunicorn \"run:app\" --bind=0.0.0.0:5000 --worker-tmp-dir /app/tmp\n    volumes:\n      - .:/app\n    # --- [THE LOOP-BREAKER FIX] ---"}
{"id": 13, "path": "e for Gitpod", "start": 0, "end": 1200, "len": 1200, "preview": "\u001b[1mdiff --git a/app/services/generation_service.py b/app/services/generation_service.py\u001b[m\n\u001b[1mindex 52e96c2..7c2d4f8 100644\u001b[m\n\u001b[1m--- a/app/services/generation_service.py\u001b[m\n\u001b[1m+++ b/app/services/"}
{"id": 14, "path": "e for Gitpod", "start": 1000, "end": 2200, "len": 1200, "preview": "+\u001b[m\u001b[32m    Core function, now with the Active Memory Protocol. It ALWAYS fetches\u001b[m\n\u001b[32m+\u001b[m\u001b[32m    context first to provide the AI with a project-aware mindset.\u001b[m\n     \"\"\"\u001b[m\n     try:\u001b[m\n\u001b[32m+"}
{"id": 15, "path": "e for Gitpod", "start": 2000, "end": 3200, "len": 1200, "preview": "lts.get('documents') and results['documents'][0] else \"No specific code context found.\"\u001b[m\n\u001b[32m+\u001b[m\u001b[32m            sources = [meta['source'] for meta in results['metadatas'][0]] if results.get('meta"}
{"id": 16, "path": "e for Gitpod", "start": 3000, "end": 4200, "len": 1200, "preview": ". First call to the AI: \"Decide if you need a tool\"\u001b[m\n\u001b[31m-        response = client.chat.completions.create(\u001b[m\n\u001b[31m-            model=\"openai/gpt-4o\",\u001b[m\n\u001b[31m-            messages=messages,\u001b[m\n\u001b"}
{"id": 17, "path": "e for Gitpod", "start": 4000, "end": 5200, "len": 1200, "preview": "if function_name in agent_tools.available_tools:\u001b[m\n\u001b[31m-                function_to_call = agent_tools.available_tools[function_name]\u001b[m\n\u001b[31m-                function_args = json.loads("}
{"id": 18, "path": "e for Gitpod", "start": 5000, "end": 6200, "len": 1200, "preview": "ant.\u001b[m\n \u001b[m\n\u001b[31m-        # 3. If no tool was called, proceed with the \"slow path\" (Code/Chat Generation)\u001b[m\n\u001b[31m-        else:\u001b[m\n\u001b[31m-            # Fetch context from ChromaDB for general queries"}
{"id": 19, "path": "e for Gitpod", "start": 6000, "end": 7200, "len": 1200, "preview": "t's less critical\u001b[m\n\u001b[31m-            code_keywords = [\"create\", \"implement\", \"generate\", \"refactor\", \"add\", \"write\", \"fix\"]\u001b[m\n\u001b[31m-            intent = \"CODE\" if any(k in prompt.lower() for k in c"}
{"id": 20, "path": "e for Gitpod", "start": 7000, "end": 8200, "len": 1200, "preview": "Analyze the user's request based on the provided context and respond with the most helpful, expert-level answer possible. If the request is to generate code, provide only the raw code. If it's a ques"}
{"id": 21, "path": "e for Gitpod", "start": 8000, "end": 8716, "len": 716, "preview": "ًا النموذج الأقوى\u001b[m\n\u001b[32m+\u001b[m\u001b[32m            messages=[\u001b[m\n\u001b[32m+\u001b[m\u001b[32m                {\"role\": \"system\", \"content\": \"You are a world-class software architect integrated into a specific project.\"}"}
{"id": 22, "path": "entrypoint.sh", "start": 0, "end": 835, "len": 835, "preview": "#!/bin/sh\n# entrypoint.sh - v9.3 (The Dual-Authority Protocol)\nset -e\n\n# --- المرحلة الأولى: مرحلة السلطة العليا (تنفيذ كـ root) ---\n# يتم تشغيل هذا الجزء من السكربت بواسطة root بشكل افتراضي.\n\necho \">"}
{"id": 23, "path": "requirements.txt", "start": 0, "end": 1026, "len": 1026, "preview": "# requirements.txt - The Strict Compatibility & Optimized Resource Protocol (vFinal)\n\n# --- [RESOURCE OPTIMIZATION & COMPATIBILITY PROTOCOL] ---\n# 1. We tell pip to find CPU-specific torch packages fi"}
{"id": 24, "path": "run.py", "start": 0, "end": 270, "len": 270, "preview": "# run.py - The Application Entry Point\n\nimport os\nfrom app import create_app\n\n# We get the environment from FLASK_ENV, defaulting to 'development'\nconfig_name = os.getenv('FLASK_ENV', 'development')\na"}
{"id": 25, "path": "cli.py", "start": 0, "end": 1200, "len": 1200, "preview": "# cli.py - The World-Awakening Entrypoint (v2.0)\n\nimport os\nimport typer\nfrom app import create_app\nfrom app.cli.main import app as typer_app\n\n# --- [THE WORLD-AWAKENING PROTOCOL] ---\n# STEP 1: We for"}
{"id": 26, "path": "cli.py", "start": 1000, "end": 1435, "len": 435, "preview": "# STEP 4: (CRITICAL) We wrap the execution of our Typer CLI\n    # within the Flask application's context.\n    # This is the \"magic\" that solves the 'Working outside of application context' error."}
{"id": 27, "path": "ai_service/Dockerfile", "start": 0, "end": 793, "len": 793, "preview": "# Dockerfile for AI Service - v4.0 (Simplified & Direct Execution)\nFROM python:3.12-bullseye\n\nENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1\n\nWORKDIR /code\n\nCOPY ./requirements.txt /code/requirement"}
{"id": 28, "path": "ai_service/entrypoint.sh", "start": 0, "end": 324, "len": 324, "preview": "#!/bin/sh\n# ai_service/entrypoint.sh - v6.0 (The Final Ignition Protocol for the AI Core)\nset -e\n\n# This script trusts the orchestration of docker-compose completely.\n# Its only job is to ignite the U"}
{"id": 29, "path": "ai_service/main.py", "start": 0, "end": 1200, "len": 1200, "preview": "# ai_service/main.py - The All-Knowing AI Oracle v5.2 (Code Generation Enabled)\n\nimport os\nfrom fastapi import FastAPI, Depends, HTTPException, Body\nfrom pydantic import BaseModel\nfrom dotenv import l"}
{"id": 30, "path": "ai_service/main.py", "start": 1000, "end": 2200, "len": 1200, "preview": "ine)\n        print(\"✅ [AI Oracle] Database connection pool forged.\")\n    except Exception as e:\n        print(f\"❌ [AI Oracle] FATAL: Could not connect to database: {e}\")\n        app.state.db_session_f"}
{"id": 31, "path": "ai_service/main.py", "start": 2000, "end": 3200, "len": 1200, "preview": "---\ndef get_db():\n    if not app.state.db_session_factory:\n        raise HTTPException(status_code=503, detail=\"Database service is unavailable.\")\n    db = app.state.db_session_factory()\n    try:"}
{"id": 32, "path": "ai_service/main.py", "start": 3000, "end": 4200, "len": 1200, "preview": "messages=messages)\n        return {\"status\": \"success\", \"data\": completion.choices[0].message.content}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n# --- [TH"}
{"id": 33, "path": "ai_service/main.py", "start": 4000, "end": 5200, "len": 1200, "preview": "e context, provide the complete, ready-to-use\n    Python code for the new feature or modification. Only output the raw code,\n    without any explanations, comments, or markdown formatting like ```pyth"}
{"id": 34, "path": "ai_service/main.py", "start": 5000, "end": 6200, "len": 1200, "preview": "s/ai-connection\", tags=[\"Diagnostics\"])\ndef test_ai_connection(client: openai.OpenAI = Depends(get_ai_client)):\n    \"\"\"Performs a LIVE test of the connection to the AI model provider.\"\"\"\n    try:"}
{"id": 35, "path": "ai_service/main.py", "start": 6000, "end": 6442, "len": 442, "preview": "l_users(db: Session = Depends(get_db)):\n    \"\"\"Directly queries and returns a list of all users.\"\"\"\n    try:\n        users_query = db.execute(text(\"SELECT id, full_name, email FROM public.user ORDER B"}
{"id": 36, "path": "ai_service/requirements.txt", "start": 0, "end": 91, "len": 91, "preview": "fastapi\nuvicorn[standard]\nsqlalchemy\npsycopg2-binary\npython-dotenv\nopenai\npython-multipart"}
{"id": 37, "path": "app/__init__.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/__init__.py - The Unified, Environment-Aware & Self-Logging Factory (v9.1 - Final)\n\nimport os\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom flask import Flask\nfrom config"}
{"id": 38, "path": "app/__init__.py", "start": 1000, "end": 2200, "len": 1200, "preview": "[STEP 2.1: CONSTITUTIONAL IMPRINTING] ---\n    config_object = config_by_name.get(config_name)\n    app.config.from_object(config_object)\n\n    # --- [STEP 2.2: ORGAN-TO-BRAIN SYNAPTIC CONNECTION] ---"}
{"id": 39, "path": "app/__init__.py", "start": 2000, "end": 3003, "len": 1003, "preview": "lueprint(user_commands.users_cli)\n        app.register_blueprint(system_commands.system_cli)\n        app.register_blueprint(mindgate_commands.mindgate_cli)\n\n    # We must import models at the end to m"}
{"id": 40, "path": "app/forms.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/forms.py\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, Email, EqualTo, ValidationError\nfrom app.models"}
{"id": 41, "path": "app/forms.py", "start": 1000, "end": 1277, "len": 277, "preview": "s=[DataRequired(), Email()])\n    password = PasswordField('Password', validators=[DataRequired()])\n    submit = SubmitField('Login')\n\nclass SubmissionForm(FlaskForm):\n    answer = StringField('Your An"}
{"id": 42, "path": "app/models.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/models.py - The Self-Learning Akashic Records (Wisdom Engine Enabled)\n\nimport uuid\nfrom datetime import datetime, UTC\nfrom app import db, login_manager\nfrom flask_login import UserMixin\nfrom wer"}
{"id": 43, "path": "app/models.py", "start": 1000, "end": 2200, "len": 1200, "preview": "ersations = db.relationship('Conversation', backref='user', lazy='dynamic', cascade=\"all, delete-orphan\")\n\n    def set_password(self, password):\n        self.password_hash = generate_password_hash(pas"}
{"id": 44, "path": "app/models.py", "start": 2000, "end": 3200, "len": 1200, "preview": ", db.ForeignKey('subjects.id'), nullable=False)\n    exercises = db.relationship('Exercise', backref='lesson', lazy='dynamic', cascade=\"all, delete-orphan\")\n    def __repr__(self):\n        return f'<Le"}
{"id": 45, "path": "app/models.py", "start": 3000, "end": 4200, "len": 1200, "preview": "me.now(UTC))\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    exercise_id = db.Column(db.Integer, db.ForeignKey('exercises.id'), nullable=False)\n\n    def __repr__(sel"}
{"id": 46, "path": "app/models.py", "start": 4000, "end": 4764, "len": 764, "preview": "reignKey('conversations.id'), nullable=False)\n    role = db.Column(db.String(50), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    timestamp = db.Column(db.DateTime, default=lambda"}
{"id": 47, "path": "app/routes.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/routes.py - The COMPLETE Main User-Facing Blueprint v3.1\nfrom flask import render_template, flash, redirect, url_for, Blueprint\nfrom flask_login import current_user, login_user, logout_user, log"}
{"id": 48, "path": "app/routes.py", "start": 1000, "end": 2200, "len": 1200, "preview": "rm.full_name.data, email=form.email.data)\n        user.set_password(form.password.data)\n        db.session.add(user)\n        db.session.commit()\n        flash('Your account has been created! You are n"}
{"id": 49, "path": "app/routes.py", "start": 2000, "end": 3200, "len": 1200, "preview": "in_required\ndef logout():\n    logout_user()\n    return redirect(url_for('main.home'))\n\n# --- Content and Learning Routes ---\n\n@bp.route('/subjects')\n@login_required\ndef subjects_list():\n    subjects ="}
{"id": 50, "path": "app/routes.py", "start": 3000, "end": 3809, "len": 809, "preview": "ise.query.get_or_404(exercise_id)\n    form = SubmissionForm()\n    if form.validate_on_submit():\n        student_answer = form.answer.data.strip()\n        is_correct = (student_answer.lower() == exerci"}
{"id": 51, "path": "migrations/README", "start": 0, "end": 41, "len": 41, "preview": "Single-database configuration for Flask."}
{"id": 52, "path": "migrations/alembic.ini", "start": 0, "end": 857, "len": 857, "preview": "# A generic, single database configuration.\n\n[alembic]\n# template used to generate migration files\n# file_template = %%(rev)s_%%(slug)s\n\n# set to 'true' to run the environment during\n# the 'revision'"}
{"id": 53, "path": "migrations/env.py", "start": 0, "end": 1200, "len": 1200, "preview": "import logging\nfrom logging.config import fileConfig\n\nfrom flask import current_app\n\nfrom alembic import context\n\n# this is the Alembic Config object, which provides\n# access to the values within the"}
{"id": 54, "path": "migrations/env.py", "start": 1000, "end": 2200, "len": 1200, "preview": "om myapp import mymodel\n# target_metadata = mymodel.Base.metadata\nconfig.set_main_option('sqlalchemy.url', get_engine_url())\ntarget_db = current_app.extensions['migrate'].db\n\n# other values from the c"}
{"id": 55, "path": "migrations/env.py", "start": 2000, "end": 3200, "len": 1200, "preview": "ontext.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate"}
{"id": 56, "path": "migrations/env.py", "start": 3000, "end": 3344, "len": 344, "preview": "ble.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=get_metadata(),\n            **conf_args\n        )\n\n        with context.begin_tra"}
{"id": 57, "path": "tests/conftest.py", "start": 0, "end": 1200, "len": 1200, "preview": "# tests/conftest.py - Final Version using TestingConfig\nimport pytest\nfrom app import create_app, db\nfrom app.models import Subject, Lesson, Exercise\nfrom config import TestingConfig # <-- 1. استيراد"}
{"id": 58, "path": "tests/conftest.py", "start": 1000, "end": 1215, "len": 215, "preview": "yield app\n\n        db.drop_all()\n\n@pytest.fixture(scope='module')\ndef test_client(test_app):\n    \"\"\"\n    يقوم بإنشاء \"متصفح وهمي\" (Test Client) لإرسال طلبات HTTP للتطبيق.\n    \"\"\"\n    return test_ap"}
{"id": 59, "path": "tests/test_app.py", "start": 0, "end": 1200, "len": 1200, "preview": "# tests/test_app.py\n\ndef test_home_page(test_client):\n    \"\"\"\n    GIVEN a Flask application configured for testing\n    WHEN the '/' page is requested (GET)\n    THEN check that the response is valid"}
{"id": 60, "path": "tests/test_app.py", "start": 1000, "end": 2138, "len": 1138, "preview": "تسجيل الدخول\n    assert b\"Log In\" in response.data\n\ndef test_successful_login_and_logout(test_client):\n    \"\"\"\n    GIVEN a user has been registered\n    WHEN they log in and then log out\n    THEN chec"}
{"id": 61, "path": "app/admin/__init__.py", "start": 0, "end": 154, "len": 154, "preview": "from flask import Blueprint\n# نعطي المخطط اسمًا فريدًا 'admin'\nbp = Blueprint('admin', __name__, template_folder='templates')\nfrom app.admin import routes"}
{"id": 62, "path": "app/admin/routes.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/admin/routes.py - The Immortal Memory Commander (v7.1 - Final & Hardened)\n\nfrom flask import render_template, abort, request, jsonify, flash, current_app # <-- [THE ULTIMATE FIX]\nfrom flask_logi"}
{"id": 63, "path": "app/admin/routes.py", "start": 1000, "end": 2200, "len": 1200, "preview": "\"\"\n    conversation_id = None # Initialize to None for safety\n    try:\n        # --- [IMMORTAL MEMORY PROTOCOL - STEP 1: INITIATION] ---\n        new_conversation = Conversation(user_id=current_user.id"}
{"id": 64, "path": "app/admin/routes.py", "start": 2000, "end": 3200, "len": 1200, "preview": "n_id\n    )\n\n\n# --- The API, now aware of the ongoing conversation's identity ---\n@bp.route(\"/api/generate-code\", methods=[\"POST\"])\n@admin_required\ndef handle_generate_code_from_ui():\n    \"\"\"\n    The s"}
{"id": 65, "path": "app/admin/routes.py", "start": 3000, "end": 3411, "len": 411, "preview": "protected ---\n@bp.route(\"/users\")\n@admin_required\ndef list_users():\n    \"\"\"\n    Displays a list of all users in the system.\n    \"\"\"\n    try:\n        all_users = db.session.scalars(db.select(User).orde"}
{"id": 66, "path": "app/cli/mindgate_commands.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/mindgate_commands.py - v3.1 (Defaulting to GPT-4o-mini)\n\nimport click\nimport openai\nfrom flask import Blueprint, current_app\n\n# The blueprint definition remains the same: powerful and scalab"}
{"id": 67, "path": "app/cli/mindgate_commands.py", "start": 1000, "end": 2200, "len": 1200, "preview": "ey,\n        )\n        click.secho(\"AI Client configured. The Gate is open.\", fg=\"green\")\n    except Exception as e:\n        click.secho(f\"FATAL ERROR: Could not configure AI client: {e}\", fg=\"red\")"}
{"id": 68, "path": "app/cli/mindgate_commands.py", "start": 2000, "end": 2447, "len": 447, "preview": "t openai.APITimeoutError:\n             click.secho(\"AI Error: The request timed out. The AI is taking too long to respond.\", fg=\"yellow\")\n        except Exception as e:\n            # Handle potential"}
{"id": 69, "path": "app/cli/system_commands.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/system_commands.py - The Architect's Control Panel for the Akashic Records\n\nimport click\nfrom flask import Blueprint\n\n# --- استيراد \"العقول\" المركزية ---\n# We now import the new history_serv"}
{"id": 70, "path": "app/cli/system_commands.py", "start": 1000, "end": 2200, "len": 1200, "preview": "'indexed_count'] == 0:\n        click.secho(\"\\nSystem knowledge is already up to date.\", fg=\"yellow\")\n    else:\n        click.secho(f\"\\nSuccessfully indexed/updated {result['indexed_count']} documents."}
{"id": 71, "path": "app/cli/system_commands.py", "start": 2000, "end": 3200, "len": 1200, "preview": "esult.get('total_lines', 'N/A')} in '{result.get('path', file_path)}':\", fg=\"green\")\n    else:\n        click.secho(f\"Full content of '{result.get('path', file_path)}' ({result.get('total_lines', 'N/A'"}
{"id": 72, "path": "app/cli/system_commands.py", "start": 3000, "end": 4200, "len": 1200, "preview": "response was generated.\"))\n    click.secho(\"--- [End of Response] ---\", fg=\"cyan\")\n\n\n# --- [THE WISDOM ENGINE - PHASE 3 COMMANDS] ---\n# These are the new tools to interact with the immortal conversat"}
{"id": 73, "path": "app/cli/system_commands.py", "start": 4000, "end": 5200, "len": 1200, "preview": "rsation)\", fg=\"yellow\")\n            continue\n        for msg in conv.messages:\n            role_color = {\n                \"user\": \"white\",\n                \"assistant\": \"cyan\",\n                \"tool\":"}
{"id": 74, "path": "app/cli/system_commands.py", "start": 5000, "end": 5223, "len": 223, "preview": "_db(message_id, rating)\n\n    if result.get('status') == 'success':\n        click.secho(result['message'], fg='green')\n    else:\n        click.secho(f\"Error: {result['message']}\", fg='red')\n\n# --- نهاي"}
{"id": 75, "path": "app/cli/user_commands.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/user_commands.py - A Thin Client for the User Service\n\nimport click\nfrom flask import Blueprint\nfrom app.services import user_service # <-- استيراد العقل الجديد\n\nusers_cli = Blueprint('users"}
{"id": 76, "path": "app/cli/user_commands.py", "start": 1000, "end": 1554, "len": 554, "preview": "click.secho(result['message'], fg='green')\n    else:\n        click.secho(f\"Error: {result['message']}\", fg='red')\n\n@users_cli.cli.command(\"init-admin\")\ndef initialize_admin_user():\n    \"\"\"Ensu"}
{"id": 77, "path": "app/cli/indexer.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/indexer.py - The Self-Healing, Robust Local Memory Architect (v2.1 - Final & Complete)\n\nfrom __future__ import annotations\nfrom pathlib import Path\nfrom typing import Iterable, List, Dict, T"}
{"id": 78, "path": "app/cli/indexer.py", "start": 1000, "end": 2200, "len": 1200, "preview": "S:\n        return True\n    if ext == \"\" and p.stat().st_size < 2_000_000:\n        return True\n    return False\n\ndef iter_files(root: Path) -> Iterable[Path]:\n    for p in root.rglob(\"*\"):\n        if p"}
{"id": 79, "path": "app/cli/indexer.py", "start": 2000, "end": 3200, "len": 1200, "preview": "d((i, j, chunk))\n        if j >= n:\n            break\n        i = max(j - overlap, i + 1)\n    return out\n\n_model_instance = None\ndef load_model(model_name: str | None = None):\n    \"\"\"\n    Loads the em"}
{"id": 80, "path": "app/cli/indexer.py", "start": 3000, "end": 4200, "len": 1200, "preview": "load_model(model_name)\n    dim = model.get_sentence_embedding_dimension()\n\n    all_chunks: List[Dict] = []\n    rid = 0\n    root_path = Path(root).resolve()\n\n    files_to_process = list(iter_files(roo"}
{"id": 81, "path": "app/cli/indexer.py", "start": 4000, "end": 4769, "len": 769, "preview": "encode(all_texts, normalize_embeddings=True, show_progress_bar=True)\n\n    for i, chunk_meta in enumerate(all_chunks):\n        chunk_meta[\"preview\"] = chunk_meta[\"text\"][:200].strip()\n        del chunk"}
{"id": 82, "path": "app/cli/search.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/search.py - The Local Memory Search Engine\n\nfrom __future__ import annotations\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Tuple\nimport json\nimport numpy as np\n\nINDEX_DIR ="}
{"id": 83, "path": "app/cli/search.py", "start": 1000, "end": 1551, "len": 551, "preview": "name: str) -> np.ndarray:\n    from sentence_transformers import SentenceTransformer\n    model = SentenceTransformer(model_name)\n    q = model.encode(text, normalize_embeddings=True).astype(\"float32\")"}
{"id": 84, "path": "app/cli/graph.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/graph.py - The Code Structure Analyzer\n\nfrom __future__ import annotations\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\nimport ast\nimport re\n\ndef list_py_files(root: Path) -"}
{"id": 85, "path": "app/cli/graph.py", "start": 1000, "end": 2200, "len": 1200, "preview": ": Dict[str, List[str]] = {}\n    for p in list_py_files(root):\n        mod = str(p.with_suffix(\"\")).replace(str(root) + \"/\", \"\").replace(\"/\", \".\")\n        graph.setdefault(mod, [])\n        try:"}
{"id": 86, "path": "app/cli/graph.py", "start": 2000, "end": 2482, "len": 482, "preview": "re.S) for p in patterns]\n    for p in list_py_files(root):\n        try:\n            src = p.read_text(encoding=\"utf-8\")\n        except Exception:\n            continue\n        for rx in regexes:"}
{"id": 87, "path": "app/cli/main.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/cli/main.py - The Command Definitions Hub (v2.0)\n\nfrom __future__ import annotations\nimport json\nfrom pathlib import Path\nimport typer\nfrom rich.console import Console\nfrom rich.table import Tab"}
{"id": 88, "path": "app/cli/main.py", "start": 1000, "end": 2200, "len": 1200, "preview": "beddings for semantic context.\")\ndef index(\n    root: str = typer.Option(\".\", help=\"Root path to index.\"),\n    model: str = typer.Option(None, help=\"Embedding model name.\"),\n    chunk: int = typer.Opt"}
{"id": 89, "path": "app/cli/main.py", "start": 2000, "end": 3200, "len": 1200, "preview": "table.add_row(f\"{r['score']:.3f}\", r[\"path\"], r[\"preview\"].replace(\"\\n\", \" \")[:120])\n    console.print(table)\n\n@app.command(help=\"Where is a symbol (function/class) defined?\")\ndef where(name: str):"}
{"id": 90, "path": "app/cli/main.py", "start": 3000, "end": 4200, "len": 1200, "preview": "le = Table(title=\"Most Imported Packages/Modules\", box=box.SIMPLE_HEAVY)\n    table.add_column(\"Module\"); table.add_column(\"Count\")\n    for name, c in sorted(counts.items(), key=lambda x: -x[1])[:20]:"}
{"id": 91, "path": "app/cli/main.py", "start": 4000, "end": 5200, "len": 1200, "preview": "ns unchanged, but now it will work\n    # because `cli.py` provides the necessary application context for `forge_new_code`.\n    try:\n        ctx_chunks = search(question, k=k)\n        context = \"\\n\\n\"."}
{"id": 92, "path": "app/cli/main.py", "start": 5000, "end": 5515, "len": 515, "preview": "tory=conversation)\n\n    sources = result.get(\"sources\", [])\n    console.rule(\"[bold cyan]Agent Response[/bold cyan]\")\n    console.print(result.get(\"code\") or result.get(\"message\"))\n    if sources:"}
{"id": 93, "path": "app/cli/__init__.py", "start": 0, "end": 164, "len": 164, "preview": "# app/cli/__init__.py\n# This file is intentionally left empty to act as a package marker.\n# All CLI blueprint registrations are handled directly in the app factory."}
{"id": 94, "path": "app/services/agent_tools.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/agent_tools.py - The Disciplined Arsenal (v3.0 - Final)\n\nimport json\nfrom . import repo_inspector_service\nfrom . import system_service\nfrom .refactoring_tool import RefactorTool\nfrom .l"}
{"id": 95, "path": "app/services/agent_tools.py", "start": 1000, "end": 2200, "len": 1200, "preview": "r):\n    \"\"\"\n    Intelligently refactors a file and returns a preview of the changes.\n    \"\"\"\n    refactor_tool = _get_refactor_tool()\n    result = refactor_tool.apply_code_refactoring(\n        file_pa"}
{"id": 96, "path": "app/services/agent_tools.py", "start": 2000, "end": 3200, "len": 1200, "preview": "l file count, code lines, or language distribution. Do NOT use it to answer questions about specific files or their purpose.\",\n            \"parameters\": {\"type\": \"object\", \"properties\": {}},\n        }"}
{"id": 97, "path": "app/services/agent_tools.py", "start": 3000, "end": 3966, "len": 966, "preview": ",\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"apply_code_refactoring\",\n            \"description\": \"Analyzes the code in a given file, applies specific requested"}
{"id": 98, "path": "app/services/generation_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/generation_service.py - The Active Hunter Architect (v13.0 - Final)\n\nimport json\nfrom flask import current_app\nfrom app import db\nfrom app.models import Message\nfrom .llm_client_service"}
{"id": 99, "path": "app/services/generation_service.py", "start": 1000, "end": 2200, "len": 1200, "preview": "_id}: {e}\", exc_info=True)\n\ndef forge_new_code(prompt: str, conversation_history: list = None, conversation_id: str = None) -> dict:\n    \"\"\"\n    The active hunter core of our AI. It actively uses tool"}
{"id": 100, "path": "app/services/generation_service.py", "start": 2000, "end": 3200, "len": 1200, "preview": "e, actionable answers citing exact file paths from the context.\n        - Do NOT paste raw context; you MUST synthesize it into a coherent answer. If tools fail, say so.\n        \"\"\".strip()\n        co"}
{"id": 101, "path": "app/services/generation_service.py", "start": 3000, "end": 4200, "len": 1200, "preview": "(f\"Generating passive context for last message: '{last_message_content[:100]}...'\")\n            current_context = find_related_context(last_message_content) or \"\"\n\n            guidance = \"Based on the"}
{"id": 102, "path": "app/services/generation_service.py", "start": 4000, "end": 5200, "len": 1200, "preview": "e=\"auto\")\n            response_message = response.choices[0].message\n            tool_calls = getattr(response_message, \"tool_calls\", None)\n\n            messages.append(response_message.model_dump())"}
{"id": 103, "path": "app/services/generation_service.py", "start": 5000, "end": 6200, "len": 1200, "preview": "for tool_call in tool_calls:\n                function_name = tool_call.function.name\n                try:\n                    if function_name in agent_tools.available_tools:"}
{"id": 104, "path": "app/services/generation_service.py", "start": 6000, "end": 6698, "len": 698, "preview": "error_content = f\"Error processing tool '{function_name}': {e}\"\n                    _save_message_to_db(conversation_id, \"tool\", error_content, tool_name=function_name)\n                    me"}
{"id": 105, "path": "app/services/llm_client_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/llm_client_service.py - The Central Communications Ministry\n\nimport openai\nfrom flask import current_app\n\ndef get_llm_client():\n    \"\"\"\n    Central factory for the LLM client. This is t"}
{"id": 106, "path": "app/services/llm_client_service.py", "start": 1000, "end": 1627, "len": 627, "preview": "de, request, **kwargs):\n        return f\"// REFACTORED BASED ON: {request}\\n\" + original_code\n\n    # You can add mock methods for chat completions as well\n    @property\n    def chat(self):\n        ret"}
{"id": 107, "path": "app/services/refactoring_tool.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/refactoring_tool.py - The Supercharged, Safe Refactoring Engine (v1.2 - Final & Complete)\n\nfrom __future__ import annotations\nimport difflib\nimport os\nimport shutil\nimport subprocess\nim"}
{"id": 108, "path": "app/services/refactoring_tool.py", "start": 1000, "end": 2200, "len": 1200, "preview": "oding=enc), enc\n            except UnicodeDecodeError:\n                continue\n        data = path.read_bytes()\n        return data.decode(errors=\"replace\"), \"unknown\"\n\n    def _write_atomic(self, pa"}
{"id": 109, "path": "app/services/refactoring_tool.py", "start": 2000, "end": 3200, "len": 1200, "preview": "-> Path:\n        backup = path.with_suffix(path.suffix + \".bak\")\n        shutil.copy2(path, backup)\n        return backup\n\n    def _build_diff(self, old: str, new: str, file_path: str) -> str:"}
{"id": 110, "path": "app/services/refactoring_tool.py", "start": 3000, "end": 4200, "len": 1200, "preview": "-> RefactorResult:\n        p = Path(file_path)\n        if not p.exists():\n            return RefactorResult(file_path, False, False, None, \"\", f\"File not found: {file_path}\")\n\n        try:"}
{"id": 111, "path": "app/services/refactoring_tool.py", "start": 4000, "end": 5200, "len": 1200, "preview": "{requested_changes}\n            ---\n\n            ### ORIGINAL CODE from file '{file_path}':\n            ---\n            {original}\n            ---\n            \"\"\"\n\n            completion = sel"}
{"id": 112, "path": "app/services/refactoring_tool.py", "start": 5000, "end": 5608, "len": 608, "preview": "return RefactorResult(file_path, True, False, None, diff_text, \"Dry-run: changes preview only.\")\n\n        backup_path = None\n        try:\n            if create_backup:\n                backup = self"}
{"id": 113, "path": "app/services/repo_inspector_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/repo_inspector_service.py - The Local Intelligence Division\n\nfrom pathlib import Path\nfrom typing import Dict, Any, List\n\n# قائمة المجلدات التي يجب تجاهلها عند العد والإحصاء\nIGNORED_DIR"}
{"id": 114, "path": "app/services/repo_inspector_service.py", "start": 1000, "end": 2200, "len": 1200, "preview": "for p in root_path.rglob(\"*\"):\n        if any(ignored in p.parts for ignored in IGNORED_DIRS):\n            continue\n        if p.is_file():\n            ext = p.suffix.lower() if p.suffix else \"<no-ex"}
{"id": 115, "path": "app/services/repo_inspector_service.py", "start": 2000, "end": 2375, "len": 375, "preview": "tinue\n    return total\n\ndef get_project_summary() -> Dict[str, Any]:\n    \"\"\"Provides a high-level summary of the project repository.\"\"\"\n    # Note: We assume this runs from the project root.\n    root"}
{"id": 116, "path": "app/services/system_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/system_service.py - The Architecture-Aware Akashic Records Ministry (v6.0 - Final & Complete)\n\nimport os\nfrom pathlib import Path\nfrom sentence_transformers import SentenceTransformer\nf"}
{"id": 117, "path": "app/services/system_service.py", "start": 1000, "end": 2200, "len": 1200, "preview": "es the project into the immortal Supabase/pgvector memory.\n    \"\"\"\n    try:\n        model = get_embedding_model()\n\n        documents_to_add = []\n        root_path = Path(\".\")\n        for path_obj in r"}
{"id": 118, "path": "app/services/system_service.py", "start": 2000, "end": 3200, "len": 1200, "preview": "ode_documents (\n                    id TEXT PRIMARY KEY, content TEXT, source TEXT, embedding VECTOR(384));\n            \"\"\"))\n\n            if force:\n                current_app.logger.info(\"Force re-i"}
{"id": 119, "path": "app/services/system_service.py", "start": 3000, "end": 4200, "len": 1200, "preview": "ssion.execute(text(\"\"\"\n                    INSERT INTO code_documents (id, content, source, embedding)\n                    VALUES (:id, :content, :source, :embedding)\n                \"\"\"), {"}
{"id": 120, "path": "app/services/system_service.py", "start": 4000, "end": 5200, "len": 1200, "preview": "rn {\"status\": \"error\", \"message\": f\"An unexpected error occurred: {e}\"}\n\ndef find_related_context(prompt_text: str) -> str:\n    \"\"\"\n    Finds relevant context using a two-tiered, architecture-aware se"}
{"id": 121, "path": "app/services/system_service.py", "start": 5000, "end": 6200, "len": 1200, "preview": "session.execute(sql, {\n                \"query_embedding\": prompt_embedding,\n                \"limit\": n_results\n            }).fetchall()\n\n        if not results:\n            current_app.logger.info(f\""}
{"id": 122, "path": "app/services/system_service.py", "start": 6000, "end": 7200, "len": 1200, "preview": "if p.is_file():\n        current_app.logger.info(f\"Found exact path match for '{file_path}'\")\n        file_path_str = str(p)\n    else:\n        current_app.logger.warning(f\"Exact path '{file_path}' not"}
{"id": 123, "path": "app/services/system_service.py", "start": 7000, "end": 8200, "len": 1200, "preview": "M code_documents WHERE id = :file_path\")\n            result = db.session.execute(sql, {\"file_path\": file_path_str}).scalar_one_or_none()\n\n        if result is not None:\n            current_app.logger."}
{"id": 124, "path": "app/services/system_service.py", "start": 8000, "end": 9200, "len": 1200, "preview": "e trying to read the file from disk: {e}\"}\n\n# --- محرك الحكمة (Wisdom Engine) ---\ndef find_similar_conversations(prompt_text: str) -> str:\n    \"\"\"\n    Finds relevant past conversation turns, prioritiz"}
{"id": 125, "path": "app/services/system_service.py", "start": 9000, "end": 10057, "len": 1057, "preview": "ults:\n            return \"No past conversational experiences found in the archives.\"\n\n        formatted_examples = \"Here are some relevant past experiences to consider:\\n\"\n        for row in reversed("}
{"id": 126, "path": "app/services/user_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/user_service.py - The User Logic Ministry\n\nimport os\nfrom app import db\nfrom app.models import User\n\ndef get_all_users():\n    \"\"\"Retrieves all users from the database.\"\"\"\n    return db."}
{"id": 127, "path": "app/services/user_service.py", "start": 1000, "end": 2200, "len": 1200, "preview": "\"message\": str(e)}\n\ndef ensure_admin_user_exists():\n    \"\"\"\n    Ensures the admin user from .env exists and is an admin.\n    Returns a dict with status and message.\n    \"\"\"\n    admin_email = os.geten"}
{"id": 128, "path": "app/services/user_service.py", "start": 2000, "end": 2314, "len": 314, "preview": "new_admin.set_password(admin_password)\n            db.session.add(new_admin)\n            db.session.commit()\n            return {\"status\": \"success\", \"message\": f\"Admin user '{admin_email}' created"}
{"id": 129, "path": "app/services/history_service.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/services/history_service.py - The Akashic Records Ministry\n\nfrom app import db\nfrom app.models import Conversation, Message\nfrom flask_login import current_user\nfrom sqlalchemy import exc as sql"}
{"id": 130, "path": "app/services/history_service.py", "start": 1000, "end": 2200, "len": 1200, "preview": "Finds a specific message by its ID and updates its rating.\n    This is the core function for the AI's learning feedback loop.\n    \"\"\"\n    if rating not in ['good', 'bad', 'neutral']:\n        return"}
{"id": 131, "path": "app/services/history_service.py", "start": 2000, "end": 2760, "len": 760, "preview": "o_rate.rating = rating\n        db.session.commit()\n\n        current_app.logger.info(f\"User {current_user.id} rated message {message_id} as '{rating}'.\")\n        return {\"status\": \"success\", \"message\":"}
{"id": 132, "path": "app/templates/models.py", "start": 0, "end": 1200, "len": 1200, "preview": "# app/models.py - The Supercharged Genetic Blueprint v3.0\n\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom flask_login import UserMixin\nfrom app import db, login_manager"}
{"id": 133, "path": "app/templates/models.py", "start": 1000, "end": 2096, "len": 1096, "preview": "s = db.relationship('Lesson', backref='subject', lazy=True)\n\nclass Lesson(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(150), nullable=False)\n    content"}
{"id": 134, "path": "migrations/versions/468b776c5a6a_initial_database_structure.py", "start": 0, "end": 1200, "len": 1200, "preview": "\"\"\"Initial database structure\n\nRevision ID: 468b776c5a6a\nRevises:\nCreate Date: 2025-07-29 12:32:30.388807\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifiers, used by Alembic."}
{"id": 135, "path": "migrations/versions/468b776c5a6a_initial_database_structure.py", "start": 1000, "end": 2200, "len": 1200, "preview": "ers', schema=None) as batch_op:\n        batch_op.create_index(batch_op.f('ix_users_email'), ['email'], unique=True)\n\n    op.create_table('lessons',\n    sa.Column('id', sa.Integer(), nullable=False),"}
{"id": 136, "path": "migrations/versions/468b776c5a6a_initial_database_structure.py", "start": 2000, "end": 3143, "len": 1143, "preview": ".Column('is_correct', sa.Boolean(), nullable=False),\n    sa.Column('submitted_at', sa.DateTime(), nullable=True),\n    sa.Column('user_id', sa.Integer(), nullable=False),\n    sa.Column('exercise_id', s"}
{"id": 137, "path": "migrations/versions/71b268d49b31_add_is_admin_field_to_user_model.py", "start": 0, "end": 828, "len": 828, "preview": "\"\"\"Add is_admin field to User model\n\nRevision ID: 71b268d49b31\nRevises: 468b776c5a6a\nCreate Date: 2025-08-11 09:32:12.393385\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision identifier"}
{"id": 138, "path": "migrations/versions/e7093d7dd84a_add_pks_and_conversation_history_models.py", "start": 0, "end": 1200, "len": 1200, "preview": "\"\"\"Add PKs and Conversation History models\n\nRevision ID: e7093d7dd84a\nRevises: 71b268d49b31\nCreate Date: 2025-08-21 10:46:19.397189\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n# revision ide"}
{"id": 139, "path": "migrations/versions/e7093d7dd84a_add_pks_and_conversation_history_models.py", "start": 1000, "end": 2200, "len": 1200, "preview": "on_id', sa.String(length=36), nullable=False),\n    sa.Column('role', sa.String(length=50), nullable=False),\n    sa.Column('content', sa.Text(), nullable=False),\n    sa.Column('timestamp', sa.DateTime("}
{"id": 140, "path": "migrations/versions/e7093d7dd84a_add_pks_and_conversation_history_models.py", "start": 2000, "end": 2566, "len": 566, "preview": "oincrement=False, nullable=True),\n    sa.Column('embedding', sa.NullType(), autoincrement=False, nullable=True),\n    sa.PrimaryKeyConstraint('id', name=op.f('code_documents_pkey'))\n    )\n    with op.b"}
{"id": 141, "path": "migrations/versions/8059ddf70ed8_complete_phase_3_add_rating_and_history_.py", "start": 0, "end": 863, "len": 863, "preview": "\"\"\"Complete Phase 3: Add rating and history management\n\nRevision ID: 8059ddf70ed8\nRevises: e7093d7dd84a\nCreate Date: 2025-08-21 12:12:58.920928\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\n\n#"}
