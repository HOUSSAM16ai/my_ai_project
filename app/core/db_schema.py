"""Ù…Ø¯Ù‚Ù‚ Ù…Ø®Ø·Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Database Schema Validator).

Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥ØµÙ„Ø§Ø­Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„.
ØªÙ… ÙØµÙ„Ù‡ Ø¹Ù† `database.py` ØªØ·Ø¨ÙŠÙ‚Ø§Ù‹ Ù„Ù…Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© (SRP).

Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± (Standards):
- CS50 2025: ØªÙˆØ«ÙŠÙ‚ Ø¹Ø±Ø¨ÙŠ Ø´Ø§Ù…Ù„.
- Fail-Fast: ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù…Ø¨ÙƒØ±Ø§Ù‹.
"""

import logging
import re
from typing import Final, NotRequired, TypedDict

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncConnection

from app.core.database import engine

logger = logging.getLogger(__name__)

__all__ = ["validate_schema_on_startup"]

# =============================================================================
# ğŸ›¡ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø®Ø·Ø· (Schema Configuration)
# =============================================================================

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ (whitelist Ù„Ù„Ø£Ù…Ø§Ù†)
_ALLOWED_TABLES: Final[frozenset[str]] = frozenset({"admin_conversations", "users"})

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
class TableSchemaConfig(TypedDict):
    """ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ø¬Ø¯ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""

    columns: list[str]
    auto_fix: dict[str, str]
    indexes: dict[str, str]
    index_names: NotRequired[dict[str, str]]


class SchemaValidationResult(TypedDict):
    """Ù†ØªÙŠØ¬Ø© ÙØ­Øµ Ø§Ù„Ù…Ø®Ø·Ø· Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡."""

    status: str
    checked_tables: list[str]
    missing_columns: list[str]
    fixed_columns: list[str]
    missing_indexes: list[str]
    fixed_indexes: list[str]
    errors: list[str]


REQUIRED_SCHEMA: Final[dict[str, TableSchemaConfig]] = {
    "admin_conversations": {
        "columns": [
            "id",
            "title",
            "user_id",
            "conversation_type",
            "linked_mission_id",
            "created_at",
        ],
        "auto_fix": {
            "linked_mission_id": 'ALTER TABLE "admin_conversations" ADD COLUMN IF NOT EXISTS "linked_mission_id" INTEGER'
        },
        "indexes": {
            "linked_mission_id": 'CREATE INDEX IF NOT EXISTS "ix_admin_conversations_linked_mission_id" ON "admin_conversations"("linked_mission_id")'
        },
        "index_names": {"linked_mission_id": "ix_admin_conversations_linked_mission_id"},
    },
    "users": {
        "columns": [
            "id",
            "external_id",
            "full_name",
            "email",
            "password_hash",
            "is_admin",
            "is_active",
            "status",
            "created_at",
            "updated_at",
        ],
        "auto_fix": {
            "external_id": 'ALTER TABLE "users" ADD COLUMN IF NOT EXISTS "external_id" VARCHAR(36)',
            "is_active": 'ALTER TABLE "users" ADD COLUMN IF NOT EXISTS "is_active" BOOLEAN NOT NULL DEFAULT TRUE',
            "status": 'ALTER TABLE "users" ADD COLUMN IF NOT EXISTS "status" VARCHAR(50) NOT NULL DEFAULT \'active\''
        },
        "indexes": {
            "external_id": 'CREATE UNIQUE INDEX IF NOT EXISTS "ix_users_external_id" ON "users"("external_id")'
        },
        "index_names": {"external_id": "ix_users_external_id"},
    }
}

async def _get_existing_columns(conn: AsyncConnection, table_name: str) -> set[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„."""
    dialect_name = conn.dialect.name

    if dialect_name == "sqlite":
        result = await conn.execute(
            text("SELECT * FROM pragma_table_info(:table_name)"),
            {"table_name": table_name},
        )
        return {row[1] for row in result.fetchall()}

    result = await conn.execute(
        text(
            "SELECT column_name FROM information_schema.columns "
            "WHERE table_name = :table_name"
        ),
        {"table_name": table_name},
    )
    return {row[0] for row in result.fetchall()}

async def _fix_missing_column(
    conn: AsyncConnection,
    table_name: str,
    col: str,
    auto_fix_queries: dict[str, str],
    index_queries: dict[str, str],
) -> bool:
    """Ø¥ØµÙ„Ø§Ø­ Ø¹Ù…ÙˆØ¯ Ù…ÙÙ‚ÙˆØ¯ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ù† ÙˆØ¬Ø¯."""
    if col not in auto_fix_queries:
        return False

    try:
        await conn.execute(text(auto_fix_queries[col]))
        logger.info(f"âœ… Added missing column: {table_name}.{col}")

        if col in index_queries:
            await conn.execute(text(index_queries[col]))
            logger.info(f"âœ… Created index for: {table_name}.{col}")

        return True
    except Exception as e:
        logger.error(f"âŒ Failed to fix {table_name}.{col}: {e}")
        return False

def _infer_index_name(index_query: str) -> str | None:
    """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ø³Ù… Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ù† Ø¬Ù…Ù„Ø© SQL Ø¹Ù†Ø¯ ØºÙŠØ§Ø¨ Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØµØ±ÙŠØ­Ø©.

    ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„ØªØ§Ø¨Ø¹ ÙƒØ§Ø­ØªÙŠØ§Ø· Ù„Ø¶Ù…Ø§Ù† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠØªÙ… ØªÙˆÙÙŠØ±
    Ø§Ù„Ø§Ø³Ù… Ø¨Ø´ÙƒÙ„ ÙŠØ¯ÙˆÙŠ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.
    """
    pattern = re.compile(r"INDEX(?: IF NOT EXISTS)?\s+\"([^\"]+)\"", flags=re.IGNORECASE)
    match = pattern.search(index_query)
    if match:
        return match.group(1)
    return None

async def _get_existing_indexes(conn: AsyncConnection, table_name: str) -> set[str]:
    """Ø¬Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„ØªÙØ§Ø¯ÙŠ Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§ Ù…Ø±ØªÙŠÙ†."""
    dialect_name = conn.dialect.name

    if dialect_name == "sqlite":
        result = await conn.execute(
            text("SELECT name FROM pragma_index_list(:table_name)"),
            {"table_name": table_name},
        )
        return {row[0] for row in result.fetchall()}

    result = await conn.execute(
        text("SELECT indexname FROM pg_indexes WHERE tablename = :table_name"),
        {"table_name": table_name},
    )
    return {row[0] for row in result.fetchall()}

async def _ensure_missing_indexes(
    conn: AsyncConnection,
    table_name: str,
    index_queries: dict[str, str],
    index_names: dict[str, str],
    existing_columns: set[str],
    auto_fix: bool,
) -> tuple[list[str], list[str], list[str]]:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙˆØªÙˆØ«ÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.

    Returns:
        tuple[list[str], list[str], list[str]]: (Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø§Ù„Ù…Ø«Ø¨ØªØ©ØŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡)
    """
    missing_indexes: list[str] = []
    fixed_indexes: list[str] = []
    errors: list[str] = []

    try:
        existing_indexes = await _get_existing_indexes(conn, table_name)
    except Exception as exc:
        return missing_indexes, fixed_indexes, [f"Error reading indexes for {table_name}: {exc}"]

    for key, index_query in index_queries.items():
        index_name = index_names.get(key) or _infer_index_name(index_query)

        if not index_name:
            errors.append(f"Unable to infer index name for {table_name}.{key}")
            continue

        if index_name in existing_indexes:
            continue

        if not auto_fix:
            missing_indexes.append(f"{table_name}.{index_name}")
            continue

        if key not in existing_columns:
            errors.append(
                f"Cannot create index {index_name} on {table_name} because column {key} is missing"
            )
            missing_indexes.append(f"{table_name}.{index_name}")
            continue

        try:
            await conn.execute(text(index_query))
            fixed_indexes.append(f"{table_name}.{index_name}")
            logger.info(f"âœ… Created missing index: {table_name}.{index_name}")
        except Exception as exc:
            errors.append(f"Failed to create index {table_name}.{index_name}: {exc}")
            missing_indexes.append(f"{table_name}.{index_name}")

    return missing_indexes, fixed_indexes, errors

async def validate_and_fix_schema(auto_fix: bool = True) -> SchemaValidationResult:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Schema ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„ÙÙ‡Ø§Ø±Ø³.

    Args:
        auto_fix (bool): ØªÙØ¹ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ.

    Returns:
        SchemaValidationResult: ØªÙ‚Ø±ÙŠØ± Ø¨Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø§Ù„Ø£Ù†ÙˆØ§Ø¹.
    """
    results: SchemaValidationResult = {
        "status": "ok",
        "checked_tables": [],
        "missing_columns": [],
        "fixed_columns": [],
        "missing_indexes": [],
        "fixed_indexes": [],
        "errors": [],
    }

    try:
        async with engine.connect() as conn:
            for table_name, schema_info in REQUIRED_SCHEMA.items():
                if table_name not in _ALLOWED_TABLES:
                    continue

                results["checked_tables"].append(table_name)

                try:
                    existing_columns = await _get_existing_columns(conn, table_name)
                except Exception as e:
                    results["errors"].append(f"Error checking table {table_name}: {e}")
                    continue

                required_columns = set(schema_info.get("columns", []))
                missing = required_columns - existing_columns

                if missing:
                    results["missing_columns"].extend([f"{table_name}.{col}" for col in missing])

                    if auto_fix:
                        auto_fix_queries = schema_info.get("auto_fix", {})
                        index_queries = schema_info.get("indexes", {})

                        for col in missing:
                            if await _fix_missing_column(conn, table_name, col, auto_fix_queries, index_queries):
                                results["fixed_columns"].append(f"{table_name}.{col}")

                index_queries = schema_info.get("indexes", {})
                index_names = schema_info.get("index_names", {})

                if index_queries:
                    missing_idx, fixed_idx, index_errors = await _ensure_missing_indexes(
                        conn=conn,
                        table_name=table_name,
                        index_queries=index_queries,
                        index_names=index_names,
                        existing_columns=existing_columns,
                        auto_fix=auto_fix,
                    )

                    results["missing_indexes"].extend(missing_idx)
                    results["fixed_indexes"].extend(fixed_idx)
                    results["errors"].extend(index_errors)

            if results["fixed_columns"] or results["fixed_indexes"]:
                await conn.commit()

    except Exception as e:
        results["status"] = "error"
        results["errors"].append(f"Schema validation failed: {e}")
        logger.error(f"âŒ Schema validation error: {e}")

    unresolved_columns = set(results["missing_columns"]) - set(results["fixed_columns"])
    unresolved_indexes = set(results["missing_indexes"]) - set(results["fixed_indexes"])

    if results["errors"]:
        results["status"] = "error"
    elif unresolved_columns or unresolved_indexes:
        results["status"] = "warning"

    return results

async def validate_schema_on_startup() -> None:
    """
    ÙØ­Øµ Schema Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
    """
    logger.info("ğŸ” Validating database schema... (Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ù…Ø®Ø·Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)")

    results = await validate_and_fix_schema(auto_fix=True)

    if results["status"] == "ok":
        logger.info("âœ… Schema validation passed (Ø§Ù„Ù…Ø®Ø·Ø· Ø³Ù„ÙŠÙ…)")
    elif results["fixed_columns"] or results["fixed_indexes"]:
        logger.warning(
            "âš ï¸ Schema auto-fixed: "
            f"columns={results['fixed_columns']}, indexes={results['fixed_indexes']}"
        )
    elif results["missing_columns"] or results["missing_indexes"]:
        logger.error(
            "âŒ CRITICAL: Missing schema elements: "
            f"columns={results['missing_columns']}, indexes={results['missing_indexes']}"
        )

    if results["errors"]:
        for error in results["errors"]:
            logger.error(f"   Error: {error}")
