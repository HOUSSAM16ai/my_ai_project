"""
Ø¨Ø« Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ (Admin Chat Streamer).

Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø¥Ø¯Ø§Ø±Ø© ØªØ¯ÙÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ© Ø¹Ø¨Ø± WebSocket Ø¨ÙŠÙ† Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©
ÙˆÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„.

Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©:
- **Async Iteration**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆÙ„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± Ù…Ø­Ø¬ÙˆØ¨Ø©.
- **Fail Fast**: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø£Ø­Ø¯Ø§Ø« Ø®Ø·Ø£ ÙˆØ§Ø¶Ø­Ø© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©.
- **Strict Typing**: Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Python 3.12+.
"""

from __future__ import annotations

import asyncio
import logging
from collections.abc import AsyncGenerator, Callable

from sqlalchemy.ext.asyncio import AsyncSession

from app.core.ai_gateway import AIClient
from app.core.domain.chat import AdminConversation, MessageRole
from app.services.admin.chat_persistence import AdminChatPersistence
from app.services.chat import get_chat_orchestrator
from app.services.chat.contracts import ChatStreamEvent
from app.services.chat.orchestrator import ChatOrchestrator

logger = logging.getLogger(__name__)

# Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ© ÙˆÙ…Ù†Ø¹ Ø¬Ù…Ø¹ Ø§Ù„Ù‚Ù…Ø§Ù…Ø© (Garbage Collection)
_background_tasks: set[asyncio.Task[object]] = set()


class AdminChatStreamer:
    """
    Ø¨Ø« Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ (Admin Chat Streamer).
    """

    def __init__(self, persistence: AdminChatPersistence) -> None:
        """
        ØªÙ‡ÙŠØ¦Ø© Ø¨Ø§Ø« Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.

        Args:
            persistence: Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¯Ø§Ø¦Ù… Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª.
        """
        self.persistence = persistence

    async def stream_response(
        self,
        user_id: int,
        conversation: AdminConversation,
        question: str,
        history: list[dict[str, object]],
        ai_client: AIClient,
        session_factory_func: Callable[[], AsyncSession],
        metadata: dict[str, object] | None = None,
    ) -> AsyncGenerator[ChatStreamEvent, None]:
        """
        ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©.

        Yields:
            ChatStreamEvent: Ø£Ø­Ø¯Ø§Ø« WebSocket Ù…Ù†Ø¸Ù…Ø© Ø¹Ù„Ù‰ Ø´ÙƒÙ„ Ù‚Ø§Ù…ÙˆØ³.
        """
        # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
        self._inject_system_context_if_missing(history)
        self._update_history_with_question(history, question)

        # 2. Ø¥Ø±Ø³Ø§Ù„ Ø­Ø¯Ø« Ø§Ù„ØªÙ‡ÙŠØ¦Ø©
        yield self._create_init_event(conversation)

        # 3. ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø« Ù…Ø¹ Ø§Ù„Ø­ÙØ¸
        try:
            orchestrator = get_chat_orchestrator()
            full_response: list[str] = []

            async for chunk in self._stream_with_safety_checks(
                orchestrator,
                question,
                user_id,
                conversation.id,
                ai_client,
                history,
                session_factory_func,
                full_response,
                metadata,
            ):
                yield chunk

            # 4. Ø­ÙØ¸ ÙˆØ¥Ù†Ù‡Ø§Ø¡
            await self._persist_response(conversation.id, full_response, session_factory_func)
            yield {"type": "complete", "payload": {"status": "done"}}

        except Exception as e:
            logger.error(f"ğŸ”¥ Streaming error: {e}")
            yield self._create_error_event(str(e))

    def _inject_system_context_if_missing(self, history: list[dict[str, object]]) -> None:
        """
        Ø­Ù‚Ù† Ø³ÙŠØ§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙÙ‚ÙˆØ¯Ø§Ù‹.
        """
        has_system = any(msg.get("role") == "system" for msg in history)
        if not has_system:
            try:
                from app.services.chat.context_service import get_context_service

                ctx_service = get_context_service()
                system_prompt = ctx_service.get_admin_system_prompt()
                history.insert(0, {"role": "system", "content": system_prompt})
            except Exception as e:
                logger.error(f"âš ï¸ Failed to inject Overmind context: {e}")

    def _update_history_with_question(
        self, history: list[dict[str, object]], question: str
    ) -> None:
        """
        ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯.
        """
        if not history or history[-1].get("content") != question:
            history.append({"role": "user", "content": question})

    def _create_init_event(self, conversation: AdminConversation) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø§Ù„ØªÙ‡ÙŠØ¦Ø©.
        """
        init_payload = {
            "conversation_id": conversation.id,
            "title": conversation.title,
        }
        return {"type": "conversation_init", "payload": init_payload}

    async def _stream_with_safety_checks(
        self,
        orchestrator: ChatOrchestrator,
        question: str,
        user_id: int,
        conversation_id: int,
        ai_client: AIClient,
        history: list[dict[str, object]],
        session_factory_func: Callable[[], AsyncSession],
        full_response: list[str],
        metadata: dict[str, object] | None = None,
    ) -> AsyncGenerator[ChatStreamEvent, None]:
        """
        Ø¨Ø« Ù…Ø¹ ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø³Ù„Ø§Ù…Ø© (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø¬Ù…).
        """
        # Note: We need to cast history to list[dict[str, str]] because ChatOrchestrator expects strict strings,
        # but here we deal with generic objects (usually strings).
        # In a perfect world, we'd validate, but for now we cast to satisfy type checker.
        history_casted = [{k: str(v) for k, v in x.items()} for x in history]

        async for content_part in orchestrator.process(
            question=question,
            user_id=user_id,
            conversation_id=conversation_id,
            ai_client=ai_client,
            history_messages=history_casted,
            session_factory=session_factory_func,
            metadata=metadata,
        ):
            if not content_part:
                continue

            full_response.append(content_part)

            if self._exceeds_safety_limit(full_response):
                yield self._create_size_limit_error()
                break

            yield self._create_chunk_event(content_part)

    def _exceeds_safety_limit(self, response_parts: list[str]) -> bool:
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† (100 Ø£Ù„Ù Ø­Ø±Ù).
        """
        current_size = sum(len(x) for x in response_parts)
        return current_size > 100000

    def _create_chunk_event(self, content: str) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø¬Ø²Ø¡ Ù…Ø­ØªÙˆÙ‰ (OpenAI style).
        """
        return {"type": "delta", "payload": {"content": content}}

    def _create_size_limit_error(self) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¬Ù….
        """
        return {
            "type": "error",
            "payload": {"details": "Response exceeded safety limit (100k chars). Aborting stream."},
        }

    def _create_error_event(self, error_details: str) -> ChatStreamEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ø§Ù….
        """
        return {"type": "error", "payload": {"details": error_details}}

    async def _persist_response(
        self,
        conversation_id: int,
        response_parts: list[str],
        session_factory_func: Callable[[], AsyncSession],
    ) -> None:
        """
        Ø­ÙØ¸ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
        """
        assistant_content = "".join(response_parts)
        if not assistant_content:
            assistant_content = "Error: No response received from AI service."

        try:
            async with session_factory_func() as session:
                p = AdminChatPersistence(session)
                await p.save_message(conversation_id, MessageRole.ASSISTANT, assistant_content)
            logger.info(f"âœ… Conversation {conversation_id} saved successfully.")
        except Exception as e:
            logger.error(f"âŒ Failed to save assistant message: {e}")
