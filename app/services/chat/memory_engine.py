"""
Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¹Ø±Ø¶ÙŠØ© (Episodic Memory Engine).
----------------------------------------------
ÙŠØ¯ÙŠØ± Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø°Ø§ÙƒØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ø£Ù…Ø¯ Ù„Ù„ÙˆÙƒÙ„Ø§Ø¡ØŒ Ø­ÙŠØ« ÙŠÙ‚ÙˆÙ… Ø¨ØªØ®Ø²ÙŠÙ† "Ø§Ù„ØªØ¬Ø§Ø±Ø¨" (Experiences)
ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹Ù‡Ø§ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©.

Ø§Ù„Ù…Ø¨Ø¯Ø£:
1. Ø§Ù„ØªØ°ÙƒØ± (Recall): Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø¯Ø±ÙˆØ³ Ø³Ø§Ø¨Ù‚Ø© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ.
2. Ø§Ù„ØªØ¹Ù„Ù… (Learn): ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¦Ù‡ (Reflection) ÙˆØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯.
"""

import asyncio
import os
from typing import Optional

from llama_index.core import (
    Document,
    StorageContext,
    VectorStoreIndex,
    load_index_from_storage,
)
from llama_index.core.retrievers import VectorIndexRetriever

from app.core.ai_gateway import AIClient
from app.core.logging import get_logger

logger = get_logger("memory-engine")

MEMORY_DIR = os.getenv("MEMORY_STORE_DIR", "./data/memory_store")


class EpisodicMemoryEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¹Ø±Ø¶ÙŠØ©.
    ÙŠØ³ØªØ®Ø¯Ù… VectorStore Ù„ØªØ®Ø²ÙŠÙ† ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙØ§Ø¯Ø©.
    """

    def __init__(self, storage_dir: str = MEMORY_DIR):
        self.storage_dir = storage_dir
        self.index = self._load_or_create_index()

    def _load_or_create_index(self) -> VectorStoreIndex:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ù† Ø§Ù„Ù‚Ø±Øµ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹."""
        if not os.path.exists(self.storage_dir):
            try:
                os.makedirs(self.storage_dir, exist_ok=True)
                # ØªÙ‡ÙŠØ¦Ø© ÙÙ‡Ø±Ø³ ÙØ§Ø±Øº
                index = VectorStoreIndex.from_documents([])
                index.storage_context.persist(persist_dir=self.storage_dir)
                return index
            except Exception as e:
                logger.error(f"Failed to create memory directory: {e}")
                # Fallback in-memory for read-only systems
                return VectorStoreIndex.from_documents([])

        try:
            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)
            return load_index_from_storage(storage_context)
        except Exception as e:
            logger.error(f"Failed to load memory index: {e}. Recreating.")
            return VectorStoreIndex.from_documents([])

    async def recall(self, query: str, top_k: int = 3) -> str:
        """
        Ø§Ø³ØªØ±Ø¬Ø§Ø¹ ØªØ¬Ø§Ø±Ø¨ Ø³Ø§Ø¨Ù‚Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©.
        ÙŠØ¹ÙŠØ¯ Ù†ØµØ§Ù‹ Ù…Ù†Ø³Ù‚Ø§Ù‹ ÙŠÙ…ÙƒÙ† Ø­Ù‚Ù†Ù‡ ÙÙŠ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
        """
        if not query or not self.index:
            return ""

        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹ (Retriever)
            retriever: VectorIndexRetriever = self.index.as_retriever(similarity_top_k=top_k)
            nodes = await retriever.aretrieve(query)

            if not nodes:
                return ""

            experiences = []
            for n in nodes:
                score = n.metadata.get("score", 0)
                # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ø±Ø¶: [Lesson] (Score: X)
                # Ù†Ø¹Ø·ÙŠ Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„ØªØ¬Ø§Ø±Ø¨ Ø°Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ø§Ù„ÙŠ Ø£Ùˆ Ø§Ù„Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹ (ØªØ­Ø°ÙŠØ±Ø§Øª)
                prefix = "âœ… TIP" if score >= 8 else "âš ï¸ WARNING"
                experiences.append(f"- {prefix} (Score: {score}): {n.text}")

            if not experiences:
                return ""

            header = "--- ğŸ§  PAST MEMORY & LESSONS (From Previous Interactions) ---"
            return f"{header}\n" + "\n".join(experiences) + "\n------------------------------------------------------------"

        except Exception as e:
            logger.error(f"Memory recall failed: {e}")
            return ""

    async def learn(
        self,
        ai_client: AIClient,
        query: str,
        plan: list,
        response: str,
        score: float,
        feedback: str,
    ) -> None:
        """
        Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.
        ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ "Ø§Ù„Ø¯Ø±Ø³" Ø«Ù… ØªØ®Ø²ÙŠÙ†Ù‡.
        """
        if not self.index:
            return

        # 1. Reflection: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¹Ø¨Ø±Ø©
        system_prompt = (
            "You are the 'Meta-Cognitive Module' of an intelligent agent. "
            "Your job is to analyze interaction logs and extract a strategic lesson."
        )

        user_prompt = f"""
Analyze this interaction to improve future performance.

User Query: {query}
Plan Executed: {plan}
Review Score: {score}/10
Review Feedback: {feedback}

Task:
Extract a concise "Strategic Lesson" (in Arabic).
- If the score is Low (< 8), explain clearly WHAT went wrong and WHAT to avoid.
- If the score is High (>= 8), explain the key strategy that led to success.

Output ONLY the lesson text.
"""
        try:
            # Ù†Ø³ØªØ®Ø¯Ù… generate_text Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ø±Ø³
            reflection_response = await ai_client.generate_text(
                prompt=user_prompt, system_prompt=system_prompt
            )
            lesson = reflection_response.content.strip()
        except Exception as e:
            logger.error(f"Reflection logic failed: {e}")
            # Fallback: Use feedback directly
            lesson = f"Feedback received: {feedback}"

        # 2. Storage: ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¯Ø±Ø³ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        # Ù†Ù‚ÙˆÙ… Ø¨ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø¯Ø±Ø³ØŒ ÙˆÙ†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© (Metadata)
        try:
            doc = Document(
                text=lesson,  # The embedding is based on the lesson/reflection
                metadata={
                    "original_query": query,  # To help with keyword matching if needed
                    "score": score,
                    "plan": str(plan),
                    "feedback": feedback,
                    "type": "episodic_reflection",
                },
            )

            self.index.insert(doc)

            # Offload blocking I/O to a thread
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(None, lambda: self.index.storage_context.persist(persist_dir=self.storage_dir))

            logger.info(f"Memory learned new lesson. Score: {score}")

        except Exception as e:
            logger.error(f"Failed to store memory: {e}")


# Singleton Instance
_instance: Optional[EpisodicMemoryEngine] = None


def get_memory_engine() -> EpisodicMemoryEngine:
    """Factory method to get the singleton memory engine."""
    global _instance
    if _instance is None:
        _instance = EpisodicMemoryEngine()
    return _instance
