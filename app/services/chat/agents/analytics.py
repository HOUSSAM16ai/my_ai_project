"""
ÙˆÙƒÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ (Analytics Agent) - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø®Ø§Ø±Ù‚Ø© (Superhuman Edition).

ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø¯Ù‚Ø© Ù…ØªÙ†Ø§Ù‡ÙŠØ©.
"""

from typing import AsyncGenerator

from app.core.ai_gateway import AIClient
from app.core.logging import get_logger
from app.services.chat.tools import ToolRegistry

logger = get_logger("analytics-agent")


class AnalyticsAgent:
    """
    ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙ‚Ø§Ø±ÙŠØ± ØªØ´Ø®ÙŠØµÙŠØ© "Ø¹Ø¨Ù‚Ø±ÙŠØ©".
    """

    def __init__(self, tools: ToolRegistry, ai_client: AIClient | None = None) -> None:
        self.tools = tools
        self.ai_client = ai_client

    async def process(self, context: dict[str, object]) -> AsyncGenerator[str, None]:
        """
        ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI Client Ù…Ø¨Ø§Ø´Ø±Ø©.
        """
        logger.info("Analytics agent started processing (Superhuman Mode)")

        user_id = context.get("user_id")
        if not user_id:
            yield "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­Ø¯ÙŠØ¯ Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡."
            return

        if not self.ai_client:
            yield "âš ï¸ Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ: Ù„Ù… ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¨Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."
            return

        yield "ğŸ” **Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø³Ø¬Ù„Ø§ØªÙƒ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø§Ø¯Ø«Ø§ØªÙƒ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„...**\n"

        # 1. Fetch Comprehensive Data (Chat Logs + Missions)
        try:
            data = await self.tools.execute("fetch_comprehensive_student_history", {"user_id": user_id})
        except Exception as e:
            logger.error(f"Error fetching comprehensive history: {e}")
            yield "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
            return

        # 2. Construct the Superhuman Prompt
        chat_logs = data.get("chat_history_text", "No logs.")
        missions = data.get("missions_summary", {})
        stats = data.get("profile_stats", {})

        system_prompt = (
            "You are a Superhuman Educational Analyst and Mentor (Ø§Ù„Ù…Ø±Ø´Ø¯ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ø¹Ø¨Ù‚Ø±ÙŠ).\n"
            "Your goal is to analyze the student's *entire* interaction history to provide a deep, psychological, and academic diagnosis.\n"
            "DO NOT just list stats. Analyze the *content* of their questions.\n\n"
            "Data Provided:\n"
            f"1. **Chat Logs (Last ~60 messages):**\n{chat_logs}\n\n"
            f"2. **Mission History:**\n{missions}\n\n"
            f"3. **Stats:**\n{stats}\n\n"
            "**Output Requirements:**\n"
            "- Tone: Professional, Encouraging, Highly Insightful (Arabic).\n"
            "- **Cognitive Analysis:** How does the student think? Are they confused by syntax or logic? Do they ask deep questions?\n"
            "- **Curriculum Alignment:** Where do they stand vs a standard roadmap?\n"
            "- **Weaknesses:** Specific concepts they struggled with in the chat.\n"
            "- **Actionable Plan:** 3 specific, non-generic steps.\n"
            "- Format with Markdown headers, bullet points, and emojis."
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "Ø­Ù„Ù„ Ø£Ø¯Ø§Ø¦ÙŠ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ø§ ØªØ¹Ø±ÙÙ‡ Ø¹Ù†ÙŠ."}
        ]

        # 3. Stream the AI Analysis
        yield "\n" # Spacing

        try:
            async for chunk in self.ai_client.stream_chat(messages):
                # Extract content depending on client wrapper structure
                content = ""
                if isinstance(chunk, dict):
                    # OpenAI-like format
                    choices = chunk.get("choices", [])
                    if choices:
                        delta = choices[0].get("delta", {})
                        content = delta.get("content", "")
                elif hasattr(chunk, "choices"):
                     # Object format
                     if chunk.choices:
                         content = chunk.choices[0].delta.content or ""

                if content:
                    yield content

        except Exception as exc:
            logger.error(f"AI Analysis Failed: {exc}")
            yield "\nâš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹."
