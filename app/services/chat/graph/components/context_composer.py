import re
from typing import ClassVar

from app.core.interfaces import IContextComposer
from app.services.chat.graph.domain import WriterIntent


class FirewallContextComposer(IContextComposer):
    """
    Formats the retrieved search results into a clean Markdown context,
    applying the 'Context Firewall' to hide solutions when not requested.
    """

    FORBIDDEN_KEYS: ClassVar[set[str]] = {
        "solution",
        "answer",
        "marking_scheme",
        "correction",
        "key",
        "answer_key",
        "solution_md",
    }
    SOLUTION_NODE_TYPES: ClassVar[set[str]] = {
        "solution",
        "answer",
        "marking_scheme",
        "key",
        "correction",
    }

    # Aggressive patterns to detect solution blocks embedded in content
    SOLUTION_PATTERNS: ClassVar[list[str]] = [
        r"(?i)\n(#{1,3}\s*(Solution|Answer|Correction|Marking Scheme|Key|Ø§Ù„Ø­Ù„|Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©|Ø§Ù„Ø¬ÙˆØ§Ø¨|ØªØµØ­ÙŠØ­|Ù…ÙØªØ§Ø­))[\s\S]+?(?=\n\s*\*{0,2}(#{1,3}|Exercise|Question|Ø§Ù„Ø³Ø¤Ø§Ù„|ØªÙ…Ø±ÙŠÙ†|Ø§Ù„ØªÙ…Ø±ÙŠÙ†)|$)",
        r"(?i)\n(Solution|Answer|Ø§Ù„Ø­Ù„|Ø§Ù„Ø¬ÙˆØ§Ø¨):\s*[\s\S]+?(?=\n\s*\*{0,2}(#{1,3}|Exercise|Question|Ø§Ù„Ø³Ø¤Ø§Ù„|ØªÙ…Ø±ÙŠÙ†|Ø§Ù„ØªÙ…Ø±ÙŠÙ†)|$)",
        r"(?is)\n\[(sol|solution):[^\]]+\][\s\S]+?(?=\n\s*\[(ex|exercise):|$)",
        r"(?i)\n\s*\*{0,2}Ø­Ù„\s+Ø§Ù„ØªÙ…Ø±ÙŠÙ†[\s\S]+?(?=\n\s*\*{0,2}(#{1,3}|Exercise|Question|Ø§Ù„Ø³Ø¤Ø§Ù„|ØªÙ…Ø±ÙŠÙ†|Ø§Ù„ØªÙ…Ø±ÙŠÙ†)|$)",
    ]
    SOLUTION_CAPTURE_PATTERNS: ClassVar[list[str]] = [
        r"(?is)\n\[(sol|solution):[^\]]+\][\s\S]+?(?=\n\s*\[(ex|exercise):|$)",
        r"(?is)\n\s*\*{0,2}Ø­Ù„\s+Ø§Ù„ØªÙ…Ø±ÙŠÙ†[\s\S]+?(?=\n\s*\*{0,2}(#{1,3}|Exercise|Question|Ø§Ù„Ø³Ø¤Ø§Ù„|ØªÙ…Ø±ÙŠÙ†|Ø§Ù„ØªÙ…Ø±ÙŠÙ†)|$)",
    ]
    GRADING_PATTERNS: ClassVar[list[str]] = [
        r"(?is)\n\[(grading|marking|rubric):[^\]]+\][\s\S]+?(?=\n\s*\[(ex|exercise|sol|solution):|$)",
        r"(?i)\n(#{1,3}\s*(Ø³Ù„Ù… Ø§Ù„ØªÙ†Ù‚ÙŠØ·|Ø³Ù„Ù… Ø§Ù„ØªØµØ­ÙŠØ­|marking scheme|grading scheme))[\s\S]+?(?=\n\s*\*{0,2}(#{1,3}|Exercise|Question|Ø§Ù„Ø³Ø¤Ø§Ù„|ØªÙ…Ø±ÙŠÙ†|Ø§Ù„ØªÙ…Ø±ÙŠÙ†)|$)",
    ]

    def compose(
        self,
        search_results: list[dict[str, object]],
        intent: WriterIntent,
        user_message: str,
    ) -> str:
        if not search_results:
            return ""

        allow_solution, allow_grading, show_hidden_marker = self._derive_intent_flags(intent)
        context_text = ""
        for item in search_results:
            node_type = str(item.get("type", "")).lower()
            if not allow_solution and node_type in self.SOLUTION_NODE_TYPES:
                continue

            content = str(item.get("content", ""))
            content = self._extract_requested_segment(content, user_message)
            sanitized_content = self._sanitize_content(
                content, show_hidden_marker=show_hidden_marker
            )

            solution_display = self._compose_solution_display(
                item=item,
                content=content,
                allow_solution=allow_solution,
                allow_grading=allow_grading,
                show_solution_banner=show_hidden_marker,
            )
            context_text += self._render_context_entry(
                sanitized_content=sanitized_content, solution_display=solution_display
            )

        return context_text

    def _derive_intent_flags(self, intent: WriterIntent) -> tuple[bool, bool, bool]:
        """ÙŠØ´ØªÙ‚ Ø£Ø¹Ù„Ø§Ù… Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
        allow_solution = intent in (WriterIntent.SOLUTION_REQUEST, WriterIntent.GRADING_REQUEST)
        allow_grading = intent == WriterIntent.GRADING_REQUEST
        show_hidden_marker = intent == WriterIntent.GENERAL_INQUIRY
        return allow_solution, allow_grading, show_hidden_marker

    def _sanitize_content(self, content: str, show_hidden_marker: bool) -> str:
        """
        Ø¥Ø²Ø§Ù„Ø© Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø¶Ù…Ù‘Ù†Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ù†Ù…Ø·ÙŠØ©.
        """
        sanitized = content
        replacement = (
            "\n\nðŸ”’ [HIDDEN: Potential Solution Segment Redacted from Content]\n"
            if show_hidden_marker
            else "\n\n"
        )

        for pattern in self.SOLUTION_PATTERNS:
            sanitized = re.sub(pattern, replacement, sanitized, flags=re.DOTALL)

        return sanitized

    def _compose_solution_display(
        self,
        item: dict[str, object],
        content: str,
        allow_solution: bool,
        allow_grading: bool,
        show_solution_banner: bool,
    ) -> str:
        """ÙŠØ¨Ù†ÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø­Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…."""
        if not allow_solution:
            return (
                "ðŸ”’ [SOLUTION HIDDEN: Student has NOT requested the solution yet.]"
                if show_solution_banner
                else ""
            )
        solution_data: dict[str, str] = {}
        for key in self.FORBIDDEN_KEYS:
            if val := item.get(key):
                solution_data[key] = str(val)
        if not solution_data:
            embedded_solutions = self._extract_solution_blocks(content)
            if embedded_solutions:
                solution_data["embedded_solution"] = "\n\n".join(embedded_solutions)
        grading_block = ""
        if allow_grading:
            grading_blocks = self._extract_grading_blocks(content)
            if grading_blocks:
                grading_block = "\n\n".join(grading_blocks)
        if solution_data:
            combined_sols = "\n\n".join(
                [f"**{k.title()}**:\n{v}" for k, v in solution_data.items()]
            )
            grading_section = f"\n\n### Ø³Ù„Ù… Ø§Ù„ØªÙ†Ù‚ÙŠØ· (Marking Scheme):\n{grading_block}" if grading_block else ""
            return f"### Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ (Official Solution):\n{combined_sols}{grading_section}"
        if grading_block:
            return f"### Ø³Ù„Ù… Ø§Ù„ØªÙ†Ù‚ÙŠØ· (Marking Scheme):\n{grading_block}"
        return "âš ï¸ [No official solution record found in database]"

    def _render_context_entry(self, sanitized_content: str, solution_display: str) -> str:
        """ÙŠØ¹ÙŠØ¯ ØªÙ…Ø«ÙŠÙ„ Ù†ØµÙŠ Ù…ÙˆØ­Ù‘Ø¯ Ù„ÙƒÙ„ Ø³ÙŠØ§Ù‚ ØªÙ…Ø±ÙŠÙ†."""
        solution_section = f"\n\n{solution_display}" if solution_display else ""
        return f"**Exercise Context:**\n{sanitized_content}{solution_section}\n\n---\n"

    def _extract_solution_blocks(self, content: str) -> list[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØªÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø¶Ù…Ù‘Ù†Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ØªØªÙˆÙØ± Ø­Ù‚ÙˆÙ„ Ø­Ù„ ØµØ±ÙŠØ­Ø©.
        """
        extracted: list[str] = []
        for pattern in self.SOLUTION_CAPTURE_PATTERNS:
            for match in re.finditer(pattern, content, flags=re.DOTALL):
                block = match.group(0).strip()
                if block and block not in extracted:
                    extracted.append(block)

        return extracted

    def _extract_grading_blocks(self, content: str) -> list[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØªÙ„ Ø³Ù„Ù… Ø§Ù„ØªÙ†Ù‚ÙŠØ· Ø§Ù„Ù…Ø¶Ù…Ù‘Ù†Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.
        """
        extracted: list[str] = []
        for pattern in self.GRADING_PATTERNS:
            for match in re.finditer(pattern, content, flags=re.DOTALL):
                block = match.group(0).strip()
                if block and block not in extracted:
                    extracted.append(block)
        return extracted

    def _extract_requested_segment(self, content: str, user_message: str) -> str:
        """
        ÙŠÙ‚ØªØ·Ø¹ Ø¬Ø²Ø¡Ø§Ù‹ Ù…Ø­Ø¯Ø¯Ø§Ù‹ Ù…Ù† Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø³Ø¤Ø§Ù„ Ø¨Ø¹ÙŠÙ†Ù‡.
        """
        requested_index = _extract_requested_index(user_message)
        if requested_index is None:
            return content

        extracted = _extract_section_by_index(content, requested_index)
        return extracted or content


def _extract_requested_index(user_message: str) -> int | None:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ù† ÙˆÙØ¬Ø¯.
    """
    pattern = re.compile(
        r"(Ø§Ù„Ø³Ø¤Ø§Ù„|Ø§Ù„ØªÙ…Ø±ÙŠÙ†|question|exercise)\s*(?:Ø±Ù‚Ù…\s*)?"
        r"(\d+|[Ù -Ù©]+|Ø§Ù„Ø£ÙˆÙ„|Ø£ÙˆÙ„|Ø§ÙˆÙ„|Ø§Ù„Ø«Ø§Ù†ÙŠ|Ø«Ø§Ù†ÙŠ|Ø§Ù„Ø«Ø§Ù„Ø«|Ø«Ø§Ù„Ø«|Ø§Ù„Ø±Ø§Ø¨Ø¹|Ø±Ø§Ø¨Ø¹|Ø§Ù„Ø®Ø§Ù…Ø³|Ø®Ø§Ù…Ø³|"
        r"Ø§Ù„Ø³Ø§Ø¯Ø³|Ø³Ø§Ø¯Ø³|Ø§Ù„Ø³Ø§Ø¨Ø¹|Ø³Ø§Ø¨Ø¹|Ø§Ù„Ø«Ø§Ù…Ù†|Ø«Ø§Ù…Ù†|Ø§Ù„ØªØ§Ø³Ø¹|ØªØ§Ø³Ø¹|Ø§Ù„Ø¹Ø§Ø´Ø±|Ø¹Ø§Ø´Ø±|"
        r"first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth)",
        re.IGNORECASE,
    )
    match = pattern.search(user_message)
    if not match:
        return None
    return _normalize_index_token(match.group(2))


def _extract_section_by_index(content: str, index: int) -> str | None:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø·Ø¹ Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„.
    """
    heading_pattern = re.compile(
        r"(?im)^(?:#{1,6}\s*)?(Ø§Ù„Ø³Ø¤Ø§Ù„|Ø§Ù„ØªÙ…Ø±ÙŠÙ†|question|exercise)\s*(?:Ø±Ù‚Ù…\s*)?"
        r"(\d+|[Ù -Ù©]+|Ø§Ù„Ø£ÙˆÙ„|Ø£ÙˆÙ„|Ø§ÙˆÙ„|Ø§Ù„Ø«Ø§Ù†ÙŠ|Ø«Ø§Ù†ÙŠ|Ø§Ù„Ø«Ø§Ù„Ø«|Ø«Ø§Ù„Ø«|Ø§Ù„Ø±Ø§Ø¨Ø¹|Ø±Ø§Ø¨Ø¹|Ø§Ù„Ø®Ø§Ù…Ø³|Ø®Ø§Ù…Ø³|"
        r"Ø§Ù„Ø³Ø§Ø¯Ø³|Ø³Ø§Ø¯Ø³|Ø§Ù„Ø³Ø§Ø¨Ø¹|Ø³Ø§Ø¨Ø¹|Ø§Ù„Ø«Ø§Ù…Ù†|Ø«Ø§Ù…Ù†|Ø§Ù„ØªØ§Ø³Ø¹|ØªØ§Ø³Ø¹|Ø§Ù„Ø¹Ø§Ø´Ø±|Ø¹Ø§Ø´Ø±|"
        r"first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth)\b"
    )

    matches = list(heading_pattern.finditer(content))
    if not matches:
        return None

    sections: list[tuple[int, int, int]] = []
    for idx, match in enumerate(matches, start=1):
        start = match.start()
        end = matches[idx].start() if idx < len(matches) else len(content)
        token_value = _normalize_index_token(match.group(2)) or idx
        sections.append((token_value, start, end))

    for token_value, start, end in sections:
        if token_value == index:
            return content[start:end].strip()

    if index <= len(sections):
        _, start, end = sections[index - 1]
        return content[start:end].strip()
    return None


def _normalize_index_token(token: str | None) -> int | None:
    """
    ØªØ­ÙˆÙŠÙ„ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø±Ù‚Ù… (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ) Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ø¹Ø¯Ø¯ÙŠØ©.
    """
    if not token:
        return None
    normalized = token.strip().lower()

    arabic_digits = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")
    numeric_candidate = normalized.translate(arabic_digits)
    if numeric_candidate.isdigit():
        return int(numeric_candidate)

    arabic_ordinals = {
        "Ø§Ù„Ø£ÙˆÙ„": 1,
        "Ø§ÙˆÙ„": 1,
        "Ø£ÙˆÙ„": 1,
        "Ø§Ù„Ø«Ø§Ù†ÙŠ": 2,
        "Ø«Ø§Ù†ÙŠ": 2,
        "Ø§Ù„Ø«Ø§Ù„Ø«": 3,
        "Ø«Ø§Ù„Ø«": 3,
        "Ø§Ù„Ø±Ø§Ø¨Ø¹": 4,
        "Ø±Ø§Ø¨Ø¹": 4,
        "Ø§Ù„Ø®Ø§Ù…Ø³": 5,
        "Ø®Ø§Ù…Ø³": 5,
        "Ø§Ù„Ø³Ø§Ø¯Ø³": 6,
        "Ø³Ø§Ø¯Ø³": 6,
        "Ø§Ù„Ø³Ø§Ø¨Ø¹": 7,
        "Ø³Ø§Ø¨Ø¹": 7,
        "Ø§Ù„Ø«Ø§Ù…Ù†": 8,
        "Ø«Ø§Ù…Ù†": 8,
        "Ø§Ù„ØªØ§Ø³Ø¹": 9,
        "ØªØ§Ø³Ø¹": 9,
        "Ø§Ù„Ø¹Ø§Ø´Ø±": 10,
        "Ø¹Ø§Ø´Ø±": 10,
    }
    if normalized in arabic_ordinals:
        return arabic_ordinals[normalized]

    english_ordinals = {
        "first": 1,
        "second": 2,
        "third": 3,
        "fourth": 4,
        "fifth": 5,
        "sixth": 6,
        "seventh": 7,
        "eighth": 8,
        "ninth": 9,
        "tenth": 10,
    }
    return english_ordinals.get(normalized)
