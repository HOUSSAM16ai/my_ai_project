# -*- coding: utf-8 -*-
"""
ADMIN AI SERVICE - SUPER INTELLIGENCE GATEWAY
Ultra Professional Hyper Edition
=====================================
File        : app/services/admin_ai_service.py
Version     : 1.0.0 â€¢ "OMNISCIENT-ADMIN / ULTRA-CONTEXT-AWARE"
Status      : Production / Hardened / Superintelligent
Author      : Overmind + Maestro Fusion System

MISSION (Ø§Ù„Ù…Ù‡Ù…Ø©)
-------
Ø®Ø¯Ù…Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø®Ø§Ø±Ù‚Ø© Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø¯Ù…Ù† ØªØ¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚Ø¯Ø±Ø§Øª:
  - ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Deep Indexer
  - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† System Service
  - ØªÙ†ÙÙŠØ° Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Overmind
  - Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  - ØªÙˆÙÙŠØ± ÙˆØ§Ø¬Ù‡Ø© Ù…ÙˆØ­Ø¯Ø© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

CORE CAPABILITIES (Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
-----------------
1. project_analysis() - ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
2. answer_question() - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ø°ÙƒÙŠ
3. execute_modification() - ØªÙ†ÙÙŠØ° ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
4. get_conversation_context() - Ø¬Ù„Ø¨ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ÙƒØ§Ù…Ù„
5. save_message() - Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
"""

from __future__ import annotations

import json
import os
import time
import logging
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime

from flask import current_app, has_app_context
from sqlalchemy import select, desc

from app import db
from app.models import (
    User, AdminConversation, AdminMessage,
    Mission, MissionStatus, utc_now
)

try:
    from app.services import generation_service as maestro
except ImportError:
    maestro = None

try:
    from app.services import system_service
except ImportError:
    system_service = None

try:
    from app.services import master_agent_service as overmind
except ImportError:
    overmind = None

try:
    from app.overmind.planning.deep_indexer import build_index, summarize_for_prompt
except ImportError:
    build_index = None
    summarize_for_prompt = None

try:
    from app.services.llm_client_service import get_llm_client
except ImportError:
    get_llm_client = None

logger = logging.getLogger(__name__)

MAX_CONTEXT_MESSAGES = int(os.getenv("ADMIN_AI_MAX_CONTEXT_MESSAGES", "10"))
MAX_RELATED_CONTEXT_CHUNKS = int(os.getenv("ADMIN_AI_MAX_CONTEXT_CHUNKS", "5"))
ENABLE_DEEP_INDEX = os.getenv("ADMIN_AI_ENABLE_DEEP_INDEX", "1") == "1"
DEFAULT_MODEL = os.getenv("DEFAULT_AI_MODEL", "openai/gpt-4o")


class AdminAIService:
    """
    Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ ØµÙØ­Ø© Ø§Ù„Ø£Ø¯Ù…Ù†.
    """
    
    def __init__(self):
        self.logger = logger
    
    def analyze_project(
        self, 
        user: User,
        conversation_id: Optional[int] = None,
        focus_areas: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Deep Indexer.
        
        Args:
            user: Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙŠ ÙŠØ·Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            conversation_id: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            focus_areas: Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„ØªØ±ÙƒÙŠØ² (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ù…Ø«Ù„ ["security", "performance", "architecture"]
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„
        """
        start_time = time.time()
        
        try:
            if build_index and ENABLE_DEEP_INDEX:
                self.logger.info(f"Building deep index for project analysis (user_id={user.id})")
                index = build_index(root=".")
                
                analysis = {
                    "status": "success",
                    "timestamp": datetime.utcnow().isoformat(),
                    "user_id": user.id,
                    "project_stats": {
                        "files_scanned": index.get("files_scanned", 0),
                        "total_functions": index.get("global_metrics", {}).get("total_functions", 0),
                        "total_classes": len([c for m in index.get("modules", []) for c in m.get("classes", [])]),
                        "complexity_hotspots": len(index.get("complexity_hotspots_top50", [])),
                        "duplicate_functions": len(index.get("duplicate_function_bodies", {})),
                    },
                    "architecture": self._analyze_architecture(index),
                    "hotspots": self._analyze_hotspots(index),
                    "recommendations": self._generate_recommendations(index),
                    "deep_index_summary": summarize_for_prompt(index, max_len=3000) if summarize_for_prompt else None,
                    "full_index": index,
                    "elapsed_seconds": round(time.time() - start_time, 2)
                }
                
                if conversation_id:
                    self._save_analysis_to_conversation(conversation_id, analysis)
                
                return analysis
            else:
                return {
                    "status": "error",
                    "error": "Deep indexer not available",
                    "elapsed_seconds": round(time.time() - start_time, 2)
                }
                
        except Exception as e:
            self.logger.error(f"Project analysis failed: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "elapsed_seconds": round(time.time() - start_time, 2)
            }
    
    def _analyze_architecture(self, index: Dict) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©"""
        layers = index.get("layers", {})
        return {
            "layers_detected": list(layers.keys()),
            "services_count": len(layers.get("service", [])),
            "models_count": len(layers.get("model", [])),
            "routes_count": len(layers.get("route", [])),
            "utils_count": len(layers.get("util", [])),
        }
    
    def _analyze_hotspots(self, index: Dict) -> List[Dict]:
        """ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ¹Ù‚ÙŠØ¯"""
        hotspots = index.get("complexity_hotspots_top50", [])[:10]
        return [
            {
                "file": h.get("file"),
                "function": h.get("name"),
                "complexity": h.get("complexity"),
                "lines": h.get("loc"),
            }
            for h in hotspots
        ]
    
    def _generate_recommendations(self, index: Dict) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ©"""
        recommendations = []
        
        hotspots_count = len(index.get("complexity_hotspots_top50", []))
        if hotspots_count > 20:
            recommendations.append(
                f"âš ï¸ ÙˆØ¬Ø¯ {hotspots_count} Ø¯Ø§Ù„Ø© Ø°Ø§Øª ØªØ¹Ù‚ÙŠØ¯ Ø¹Ø§Ù„ÙŠ. ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¹Ø§Ø¯Ø© Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©."
            )
        
        duplicates_count = len(index.get("duplicate_function_bodies", []))
        if duplicates_count > 5:
            recommendations.append(
                f"âš ï¸ ÙˆØ¬Ø¯ {duplicates_count} Ø¯Ø§Ù„Ø© Ù…ÙƒØ±Ø±Ø©. ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬Ù‡Ø§ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙŠØ§Ù†Ø©."
            )
        
        files = index.get("file_metrics", [])
        large_files = [f for f in files if f.get("loc", 0) > 500]
        if large_files:
            recommendations.append(
                f"ðŸ“„ ÙŠÙˆØ¬Ø¯ {len(large_files)} Ù…Ù„Ù ÙƒØ¨ÙŠØ± (>500 Ø³Ø·Ø±). ÙŠÙÙ†ØµØ­ Ø¨ØªÙ‚Ø³ÙŠÙ…Ù‡Ø§."
            )
        
        return recommendations
    
    def _save_analysis_to_conversation(self, conversation_id: int, analysis: Dict):
        """Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        try:
            conv = db.session.get(AdminConversation, conversation_id)
            if conv:
                conv.deep_index_summary = analysis.get("deep_index_summary")
                conv.context_snapshot = {
                    "project_stats": analysis.get("project_stats"),
                    "architecture": analysis.get("architecture"),
                    "timestamp": analysis.get("timestamp")
                }
                db.session.commit()
        except Exception as e:
            self.logger.error(f"Failed to save analysis to conversation: {e}")
    
    def answer_question(
        self,
        question: str,
        user: User,
        conversation_id: Optional[int] = None,
        use_deep_context: bool = True
    ) -> Dict[str, Any]:
        """
        Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹.
        
        Args:
            question: Ø§Ù„Ø³Ø¤Ø§Ù„
            user: Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            conversation_id: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            use_deep_context: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¹Ù…ÙŠÙ‚
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        """
        start_time = time.time()
        
        try:
            conversation_history = []
            deep_index_summary = None
            
            if conversation_id:
                conversation_history = self._get_conversation_history(conversation_id)
                conv = db.session.get(AdminConversation, conversation_id)
                if conv and conv.deep_index_summary:
                    deep_index_summary = conv.deep_index_summary
            
            related_context = []
            if system_service and hasattr(system_service, 'find_related_context'):
                try:
                    ctx_result = system_service.find_related_context(
                        question, 
                        limit=MAX_RELATED_CONTEXT_CHUNKS
                    )
                    if ctx_result.ok:
                        related_context = ctx_result.data.get("results", [])
                except Exception as e:
                    self.logger.warning(f"Failed to get related context: {e}")
            
            system_prompt = self._build_super_system_prompt(
                deep_index_summary=deep_index_summary if use_deep_context else None,
                related_context=related_context
            )
            
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(conversation_history[-MAX_CONTEXT_MESSAGES:])
            messages.append({"role": "user", "content": question})
            
            if get_llm_client:
                client = get_llm_client()
                response = client.chat.completions.create(
                    model=DEFAULT_MODEL,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=2000
                )
                
                answer = response.choices[0].message.content
                tokens_used = getattr(response.usage, 'total_tokens', None)
                model_used = response.model
                
            else:
                answer = "Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."
                tokens_used = None
                model_used = None
            
            elapsed = round(time.time() - start_time, 2)
            
            if conversation_id:
                self._save_message(conversation_id, "user", question)
                self._save_message(
                    conversation_id, 
                    "assistant", 
                    answer,
                    tokens_used=tokens_used,
                    model_used=model_used,
                    latency_ms=elapsed * 1000
                )
            
            return {
                "status": "success",
                "question": question,
                "answer": answer,
                "tokens_used": tokens_used,
                "model_used": model_used,
                "related_context_count": len(related_context),
                "used_deep_index": deep_index_summary is not None,
                "elapsed_seconds": elapsed
            }
            
        except Exception as e:
            self.logger.error(f"Question answering failed: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "elapsed_seconds": round(time.time() - start_time, 2)
            }
    
    def _build_super_system_prompt(
        self,
        deep_index_summary: Optional[str] = None,
        related_context: Optional[List[Dict]] = None
    ) -> str:
        """Ø¨Ù†Ø§Ø¡ System Prompt Ø®Ø§Ø±Ù‚ Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        parts = [
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø®Ø§Ø±Ù‚ ÙˆÙ…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ ÙˆÙÙ‡Ù… Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©.",
            "Ù„Ø¯ÙŠÙƒ Ù…Ø¹Ø±ÙØ© Ø¹Ù…ÙŠÙ‚Ø© Ø¨Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆÙƒÙ„ ØªÙØ§ØµÙŠÙ„Ù‡.",
            "\n## Ù‚Ø¯Ø±Ø§ØªÙƒ:",
            "- ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù„ÙƒÙˆØ¯ ÙˆØ§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©",
            "- Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø¹Ù‚Ø¯Ø©",
            "- Ø§Ù‚ØªØ±Ø§Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆØ­Ù„ÙˆÙ„",
            "- ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©",
            "\n## Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:",
            "- Ù…Ù†Ø¸Ù… ÙˆÙ…Ù‡Ù†ÙŠ",
            "- ÙŠØ³ØªØ®Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙØ¹Ù„ÙŠ",
            "- ÙŠØ´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶ÙˆØ­",
            "- ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚",
        ]
        
        if deep_index_summary:
            parts.extend([
                "\n## Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:",
                deep_index_summary
            ])
        
        if related_context:
            parts.append("\n## Ø³ÙŠØ§Ù‚ Ø°Ùˆ ØµÙ„Ø©:")
            for i, ctx in enumerate(related_context[:3], 1):
                parts.append(f"\n### Ù…Ù‚Ø·Ø¹ {i} Ù…Ù† {ctx.get('file_path', 'unknown')}:")
                parts.append(ctx.get('content', '')[:500])
        
        return "\n".join(parts)
    
    def execute_modification(
        self,
        objective: str,
        user: User,
        conversation_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ØªÙ†ÙÙŠØ° ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Overmind.
        
        Args:
            objective: Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            user: Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            conversation_id: Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        
        Returns:
            Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†ÙÙŠØ°
        """
        start_time = time.time()
        
        try:
            if not overmind:
                return {
                    "status": "error",
                    "error": "Overmind service not available",
                    "elapsed_seconds": round(time.time() - start_time, 2)
                }
            
            self.logger.info(f"Creating mission for objective: {objective}")
            mission = overmind.start_mission(objective=objective, initiator=user)
            
            if conversation_id:
                self._save_message(
                    conversation_id,
                    "system",
                    f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© (Mission #{mission.id}) Ù„ØªÙ†ÙÙŠØ°: {objective}",
                    metadata_json={"mission_id": mission.id, "objective": objective}
                )
            
            return {
                "status": "success",
                "mission_id": mission.id,
                "objective": objective,
                "mission_status": mission.status.value,
                "message": f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­. ÙŠÙ…ÙƒÙ†Ùƒ Ù…ØªØ§Ø¨Ø¹Ø© ØªÙ‚Ø¯Ù…Ù‡Ø§ Ù…Ù† ØµÙØ­Ø© Mission #{mission.id}",
                "elapsed_seconds": round(time.time() - start_time, 2)
            }
            
        except Exception as e:
            self.logger.error(f"Modification execution failed: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "elapsed_seconds": round(time.time() - start_time, 2)
            }
    
    def create_conversation(
        self,
        user: User,
        title: str,
        conversation_type: str = "general"
    ) -> AdminConversation:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        conv = AdminConversation(
            title=title,
            user_id=user.id,
            conversation_type=conversation_type
        )
        db.session.add(conv)
        db.session.commit()
        return conv
    
    def _get_conversation_history(self, conversation_id: int) -> List[Dict[str, str]]:
        """Ø¬Ù„Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        messages = db.session.scalars(
            select(AdminMessage)
            .where(AdminMessage.conversation_id == conversation_id)
            .order_by(AdminMessage.created_at)
        ).all()
        
        return [
            {"role": msg.role, "content": msg.content}
            for msg in messages
        ]
    
    def _save_message(
        self,
        conversation_id: int,
        role: str,
        content: str,
        tokens_used: Optional[int] = None,
        model_used: Optional[str] = None,
        latency_ms: Optional[float] = None,
        metadata_json: Optional[Dict] = None
    ):
        """Ø­ÙØ¸ Ø±Ø³Ø§Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
        msg = AdminMessage(
            conversation_id=conversation_id,
            role=role,
            content=content,
            tokens_used=tokens_used,
            model_used=model_used,
            latency_ms=latency_ms,
            metadata_json=metadata_json
        )
        db.session.add(msg)
        db.session.commit()
    
    def get_user_conversations(
        self,
        user: User,
        limit: int = 20
    ) -> List[AdminConversation]:
        """Ø¬Ù„Ø¨ Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        return db.session.scalars(
            select(AdminConversation)
            .where(AdminConversation.user_id == user.id)
            .order_by(desc(AdminConversation.updated_at))
            .limit(limit)
        ).all()


_service_instance = None

def get_admin_ai_service() -> AdminAIService:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ø®Ø¯Ù…Ø©"""
    global _service_instance
    if _service_instance is None:
        _service_instance = AdminAIService()
    return _service_instance
